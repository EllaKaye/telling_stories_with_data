<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 14 It’s Just A Linear Model | Telling Stories With Data</title>
<meta name="author" content="Rohan Alexander">
<meta name="description" content="Required material Read An Introduction to Statistical Learning with Applications in R, Chapters 3 ‘Linear Regression’, and 4 ‘Classification’, (James et al. 2017) Read Data Analysis Using...">
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content="Chapter 14 It’s Just A Linear Model | Telling Stories With Data">
<meta property="og:type" content="book">
<meta property="og:image" content="/tellingstorieswithdatapainting.png">
<meta property="og:description" content="Required material Read An Introduction to Statistical Learning with Applications in R, Chapters 3 ‘Linear Regression’, and 4 ‘Classification’, (James et al. 2017) Read Data Analysis Using...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 14 It’s Just A Linear Model | Telling Stories With Data">
<meta name="twitter:description" content="Required material Read An Introduction to Statistical Learning with Applications in R, Chapters 3 ‘Linear Regression’, and 4 ‘Classification’, (James et al. 2017) Read Data Analysis Using...">
<meta name="twitter:image" content="/tellingstorieswithdatapainting.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.11/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><link href="libs/_Atkinson%20Hyperlegible-0.4.0/font.css" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=IBM%20Plex%20Mono&amp;display=swap" rel="stylesheet">
<script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script><link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet">
<script src="libs/leaflet-1.3.1/leaflet.js"></script><link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet">
<script src="libs/proj4-2.6.2/proj4.min.js"></script><script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script><link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet">
<script src="libs/leaflet-binding-2.0.4.1/leaflet.js"></script><script src="libs/mapdeck-binding-0.3.4/mapdeck.js"></script><script src="libs/mpadeck_functions-0.0.1/mapdeck_functions.js"></script><script src="libs/deckgl-8.1.6/deckgl.min.js"></script><script src="libs/legend-0.0.1/legend.js"></script><script src="libs/title-0.0.1/title.js"></script><script src="libs/mapdeck_location-0.0.1/mapdeck_location.js"></script><script src="libs/mapdeck_colours-0.0.1/mapdeck_colours.js"></script><script src="libs/mapdeck_coordinates-0.0.1/mapdeck_coordinates.js"></script><link href="libs/mapboxgl-1.10.0/mapbox-gl.css" rel="stylesheet">
<script src="libs/mapboxgl-1.10.0/mapbox-gl.js"></script><link href="libs/mapdeck-0.0.1/mapdeck.css" rel="stylesheet">
<script src="libs/mpadeck-binding-0.3.4/mapdeck.js"></script><script src="libs/scatterplot-1.0.0/scatterplot.js"></script><script src="libs/viz-1.8.2/viz.js"></script><link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet">
<script src="libs/grViz-binding-1.0.6.1/grViz.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="bs4_style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Telling Stories With Data</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="about-the-author.html">About the author</a></li>
<li class="book-part">Foundations</li>
<li><a class="" href="telling-stories-with-data.html"><span class="header-section-number">1</span> Telling stories with data</a></li>
<li><a class="" href="drinking-from-a-fire-hose.html"><span class="header-section-number">2</span> Drinking from a fire hose</a></li>
<li><a class="" href="r-essentials.html"><span class="header-section-number">3</span> R essentials</a></li>
<li><a class="" href="reproducible-workflows.html"><span class="header-section-number">4</span> Reproducible workflows</a></li>
<li class="book-part">Communication</li>
<li><a class="" href="on-writing.html"><span class="header-section-number">5</span> On writing</a></li>
<li><a class="" href="static-communication.html"><span class="header-section-number">6</span> Static communication</a></li>
<li><a class="" href="interactive-communication.html"><span class="header-section-number">7</span> Interactive communication</a></li>
<li class="book-part">Acquisition</li>
<li><a class="" href="farm-data.html"><span class="header-section-number">8</span> Farm data</a></li>
<li><a class="" href="gather-data.html"><span class="header-section-number">9</span> Gather data</a></li>
<li><a class="" href="hunt-data.html"><span class="header-section-number">10</span> Hunt data</a></li>
<li class="book-part">Preparation</li>
<li><a class="" href="clean-and-prepare.html"><span class="header-section-number">11</span> Clean and prepare</a></li>
<li><a class="" href="store-and-share.html"><span class="header-section-number">12</span> Store and share</a></li>
<li class="book-part">Modelling</li>
<li><a class="" href="exploratory-data-analysis.html"><span class="header-section-number">13</span> Exploratory data analysis</a></li>
<li><a class="active" href="ijalm.html"><span class="header-section-number">14</span> It’s Just A Linear Model</a></li>
<li><a class="" href="causality.html"><span class="header-section-number">15</span> Causality from observational data</a></li>
<li><a class="" href="mrp.html"><span class="header-section-number">16</span> Multilevel regression with post-stratification</a></li>
<li><a class="" href="text-as-data.html"><span class="header-section-number">17</span> Text as data</a></li>
<li class="book-part">Enrichment</li>
<li><a class="" href="deploying-models.html"><span class="header-section-number">18</span> Deploying models</a></li>
<li><a class="" href="efficiency.html"><span class="header-section-number">19</span> Efficiency</a></li>
<li><a class="" href="concludingremarks.html"><span class="header-section-number">20</span> Concluding remarks</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="oh-you-think-and-shoulders-and-datasets.html"><span class="header-section-number">A</span> Oh you think and shoulders and datasets</a></li>
<li><a class="" href="papers.html"><span class="header-section-number">B</span> Papers</a></li>
<li><a class="" href="cocktails.html"><span class="header-section-number">C</span> Cocktails</a></li>
<li><a class="" href="references-1.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/rstudio/bookdown-demo">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="ijalm" class="section level1" number="14">
<h1>
<span class="header-section-number">14</span> It’s Just A Linear Model<a class="anchor" aria-label="anchor" href="#ijalm"><i class="fas fa-link"></i></a>
</h1>
<p><strong>Required material</strong></p>
<ul>
<li>Read <em>An Introduction to Statistical Learning with Applications in R</em>, Chapters 3 ‘Linear Regression’, and 4 ‘Classification’, <span class="citation">(<a href="references-1.html#ref-islr" role="doc-biblioref">James et al. 2017</a>)</span>
</li>
<li>Read <em>Data Analysis Using Regression and Multilevel/Hierarchical Models</em>, Chapters 3 ‘Linear regression: the basics’, 4 ‘Linear regression: before and after fitting the model’, 5 ‘Logistic regression’, and 6 ‘Generalized linear models’, <span class="citation">(<a href="references-1.html#ref-gelmanandhill" role="doc-biblioref">Gelman and Hill 2007</a>)</span>
</li>
<li>Read <em>Why most published research findings are false</em>, <span class="citation">(<a href="references-1.html#ref-ioannidis2005most" role="doc-biblioref">Ioannidis 2005</a>)</span>
</li>
</ul>
<!-- - Pavlik, Kaylin, 2018, 'Exploring the Relationship Between Dog Names and Breeds', https://www.kaylinpavlik.com/dog-names-tfidf/. --><!-- - Pavlik, Kaylin, 2019, 'Understanding + classifying genres using Spotify audio features', https://www.kaylinpavlik.com/classifying-songs-genres/. --><!-- - Silge, Julia, 2019, 'Modeling salary and gender in the tech industry', https://juliasilge.com/blog/salary-gender/. --><!-- - Silge, Julia, 2019, 'Opioid prescribing habits in Texas', https://juliasilge.com/blog/texas-opioids/. --><!-- - Silge, Julia, 2019, 'Tidymodels', https://juliasilge.com/blog/intro-tidymodels/. --><!-- - Silge, Julia, 2020, '#TidyTuesday hotel bookings and recipes', https://juliasilge.com/blog/hotels-recipes/. --><!-- - Silge, Julia, 2020, 'Hyperparameter tuning and #TidyTuesday food consumption', https://juliasilge.com/blog/food-hyperparameter-tune/. --><!-- - Taddy, Matt, 2019, *Business Data Science*, Chapters 2 and 4. --><!-- - Wasserstein, Ronald L. and Nicole A. Lazar, 2016, 'The ASA Statement on p-Values: Context, Process, and Purpose', *The American Statistician*, 70:2, 129-133, DOI: 10.1080/00031305.2016.1154108. --><!-- https://rviews.rstudio.com/2020/03/10/comparing-machine-learning-algorithms-for-predicting-clothing-classes-part-3/ --><!-- https://juliasilge.com/blog/tuition-resampling/ --><p><strong>Key concepts and skills</strong></p>
<ul>
<li>Simple and multiple linear regression.</li>
<li>Logistic and Poisson regression.</li>
<li>The key role of uncertainty.</li>
<li>Threats to validity of inference.</li>
<li>Overfitting.</li>
</ul>
<p><strong>Key libraries</strong></p>
<ul>
<li>
<code>broom</code> <span class="citation">(<a href="references-1.html#ref-broom" role="doc-biblioref">D. Robinson, Hayes, and Couch 2021</a>)</span>
</li>
<li>
<code>modelsummary</code> <span class="citation">(<a href="references-1.html#ref-citemodelsummary" role="doc-biblioref">Arel-Bundock 2021a</a>)</span>
</li>
<li>
<code>rstanarm</code> <span class="citation">(<a href="references-1.html#ref-citerstanarm" role="doc-biblioref">Goodrich et al. 2020</a>)</span>
</li>
<li>
<code>tidymodels</code> <span class="citation">(<a href="references-1.html#ref-citeTidymodels" role="doc-biblioref">Kuhn and Wickham 2020</a>)</span>
</li>
<li>
<code>tidyverse</code> <span class="citation">(<a href="references-1.html#ref-citetidyverse" role="doc-biblioref">Wickham et al. 2019a</a>)</span>
</li>
</ul>
<p><strong>Key functions</strong></p>
<ul>
<li><code><a href="https://generics.r-lib.org/reference/augment.html">broom::augment()</a></code></li>
<li><code><a href="https://generics.r-lib.org/reference/glance.html">broom::glance()</a></code></li>
<li><code><a href="https://generics.r-lib.org/reference/tidy.html">broom::tidy()</a></code></li>
<li><code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code></li>
<li><code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code></li>
<li><code><a href="https://vincentarelbundock.github.io/modelsummary/reference/modelsummary.html">modelsummary::modelsummary()</a></code></li>
<li><code><a href="https://generics.r-lib.org/reference/fit.html">parsnip::fit()</a></code></li>
<li><code><a href="https://parsnip.tidymodels.org/reference/linear_reg.html">parsnip::linear_reg()</a></code></li>
<li><code><a href="https://parsnip.tidymodels.org/reference/logistic_reg.html">parsnip::logistic_reg()</a></code></li>
<li><code><a href="https://parsnip.tidymodels.org/reference/set_engine.html">parsnip::set_engine()</a></code></li>
<li><code><a href="https://poissonreg.tidymodels.org/reference/poisson_reg.html">poissonreg::poisson_reg()</a></code></li>
<li><code><a href="https://rdrr.io/r/stats/Normal.html">rnorm()</a></code></li>
<li><code><a href="https://rdrr.io/r/stats/Poisson.html">rpois()</a></code></li>
<li><code><a href="https://rsample.tidymodels.org/reference/initial_split.html">rsample::initial_split()</a></code></li>
<li><code><a href="https://rsample.tidymodels.org/reference/initial_split.html">rsample::testing()</a></code></li>
<li><code><a href="https://rsample.tidymodels.org/reference/initial_split.html">rsample::training()</a></code></li>
<li><code><a href="https://rdrr.io/r/base/sample.html">sample()</a></code></li>
<li><code><a href="https://rdrr.io/r/base/Random.html">set.seed()</a></code></li>
<li><code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code></li>
</ul>
<div id="introduction-11" class="section level2" number="14.1">
<h2>
<span class="header-section-number">14.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-11"><i class="fas fa-link"></i></a>
</h2>
<p>Linear models have been around for a long time. For instance, speaking about the development of least squares, which is one way to fit linear models, in the 1700s, <span class="citation">Stigler (<a href="references-1.html#ref-stigler" role="doc-biblioref">1986, 16</a>)</span> describes how it was associated with foundational problems in astronomy, such as determining the motion of the moon and reconciling the non-periodic motion of Jupiter and Saturn. The fundamental issue at the time with least squares was that of hesitancy to combine different observations. Astronomers were early to develop a comfort with doing this because they had typically gathered their observations themselves and knew that the conditions of the data gathering were similar, even though the value of the observation was different. It took longer for social scientists to become comfortable with linear models, possibly because they were hesitant to group together data they worried was not alike. In this sense, astronomers had an advantage because they could compare their predictions with what actually happened whereas this was more difficult for social scientists <span class="citation">(<a href="references-1.html#ref-stigler" role="doc-biblioref">Stigler 1986, 163</a>)</span>.</p>
<p>Galton and others of his generation, some of whom were eugenicists, used linear regression in earnest in the late 1800s and early 1900s. Binary outcomes quickly became of interest and needed special treatment, leading to the development and wide adaption of logistic regression and similar methods in the mid-1900s <span class="citation">(<a href="references-1.html#ref-cramer2002origins" role="doc-biblioref">Cramer 2002</a>)</span>. The generalized linear model framework came into being, in a formal sense, in the 1970s with <span class="citation">Nelder and Wedderburn (<a href="references-1.html#ref-nelder1972generalized" role="doc-biblioref">1972</a>)</span> who brought this all together. Generalized linear models (GLM) broaden the types of outcomes that are allowed. We still model outcomes as a linear function, but we are not constrained to an outcome that is normally distributed. The outcome can be anything in the exponential family, and popular choices include the logistic distribution, and the Poisson distribution. A further generalization of GLMs is generalized additive models where we broaden the structure of the explanatory side. We still explain the dependent variable as an additive function of various bits and pieces, but those bits and pieces can be functions. This framework, in this way, came about in the 1990s, with <span class="citation">Hastie and Tibshirani (<a href="references-1.html#ref-hastie1990generalized" role="doc-biblioref">1990</a>)</span>.</p>
<p>It is important to recognize that when we build models, we are not discovering ‘the truth’. We are using the model to help us explore and understand the data that we have. There is no one best model, there are just useful models that help us learn something about the data that we have and hence, hopefully, something about the world from which the data were generated. When we use models, we are trying to understand the world, but there are enormous constraints on the perspective we bring to this. It is silly to expect one model to be universal. Further, we should not just blindly throw data into a regression model and hope that it will sort it out. ‘Regression will not sort it out. Regression is indeed an oracle, but a cruel one. It speaks in riddles and delights in punishing us for asking bad questions’ <span class="citation">(<a href="references-1.html#ref-citemcelreath" role="doc-biblioref">McElreath 2020, 162</a>)</span>.</p>
<p>We use models to understand the world. We poke, push, and test them. We build them and rejoice in their beauty, and then seek to understand their limits and ultimately destroy them. It is this process that is important, it is this process that allows us to better understand the world; not the outcome. When we build models, we need to keep in mind both the world of the model and the broader world that we want to be able to speak about. To what extent does a model trained on the experiences of straight, cis, men, speak to the world as it is? It is not worthless, but it is also not unimpeachable. To what extent does the model teach us about the data that we have? To what extent do the data that we have reflect the world about which we would like to draw conclusions? We need to keep such questions front of mind.</p>
<p>Much of statistics was developed without concern for broader implications. And that was reasonable because it was developed for situations such as astronomy and agriculture. Folks were literally able to randomize the order of fields and planting because they literally worked at agricultural stations. But many of the subsequent applications in the twentieth and twenty-first centuries, do not have those properties. Statistical science is often taught as though it proceeds through some idealized process where a hypothesis appears, is tested, and is either confirmed or not. But that is not what happens. We react to incentives. We dabble, guess, and test, and then follow our intuition, backfilling as we need. All of this is fine. But it is not a world in which a traditional null hypothesis holds completely, which means concepts such as p-values and power lose some of their meaning. While we need to understand the ‘old world’, we also need to be sophisticated enough to know when we need to move away from it. We can appreciate the beauty and ingenuity of a Ford Model T, at the same time recognizing we could not use it to win Le Mans.</p>
<p>In this chapter we begin with simple linear regression, and then move to multiple linear regression, the difference being the number of explanatory variables that we allow. We then consider logistic and Poisson regression. We consider three approaches for each of these: base R, which is useful when we want to quickly use the models in EDA; <code>tidymodels</code> <span class="citation">(<a href="references-1.html#ref-citeTidymodels" role="doc-biblioref">Kuhn and Wickham 2020</a>)</span> which is useful when we are interested in forecasting; and <code>rstanarm</code> <span class="citation">(<a href="references-1.html#ref-citerstanarm" role="doc-biblioref">Goodrich et al. 2020</a>)</span> when we are interested in understanding. Regardless of the approach we use, the important thing to remember is that modelling in this way is just fancy averaging. The chapter is named for a quote by Daniela Witten, Professor, University of Washington, who identifies how far we can get with linear models and the huge extent to which they underpin statistics.</p>
</div>
<div id="simple-linear-regression" class="section level2" number="14.2">
<h2>
<span class="header-section-number">14.2</span> Simple linear regression<a class="anchor" aria-label="anchor" href="#simple-linear-regression"><i class="fas fa-link"></i></a>
</h2>
<p>When we are interested in the relationship between two continuous variables, say <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span>, we can use simple linear regression. This is based on the Normal, also ‘Gaussian’, distribution. The shape of the Normal distribution is determined by two parameters, the mean <span class="math inline">\(\mu\)</span> and the standard deviation, <span class="math inline">\(\sigma\)</span>:</p>
<p><span class="math display">\[y = \frac{1}{\sqrt{2\pi\sigma}}e^{-\frac{1}{2}z^2},\]</span>
where <span class="math inline">\(z = (x - \mu)/\sigma\)</span> is the difference between the mean, <span class="math inline">\(\mu\)</span>, and <span class="math inline">\(x\)</span> in terms of the standard deviation <span class="citation">(<a href="references-1.html#ref-pitman" role="doc-biblioref">Pitman 1993, 94</a>)</span>.</p>
<p>As discussed in Chapter <a href="r-essentials.html#r-essentials">3</a>, we use <code><a href="https://rdrr.io/r/stats/Normal.html">rnorm()</a></code> to simulate data from the Normal distribution.</p>
<div class="sourceCode" id="cb455"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">853</span><span class="op">)</span>

<span class="va">twenty_draws_from_normal_distribution</span> <span class="op">&lt;-</span> 
  <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>draws <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">20</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
  
<span class="va">twenty_draws_from_normal_distribution</span>
<span class="co">#&gt; # A tibble: 20 × 1</span>
<span class="co">#&gt;      draws</span>
<span class="co">#&gt;      &lt;dbl&gt;</span>
<span class="co">#&gt;  1 -0.360 </span>
<span class="co">#&gt;  2 -0.0406</span>
<span class="co">#&gt;  3 -1.78  </span>
<span class="co">#&gt;  4 -1.12  </span>
<span class="co">#&gt;  5 -1.00  </span>
<span class="co">#&gt;  6  1.78  </span>
<span class="co">#&gt;  7 -1.39  </span>
<span class="co">#&gt;  8 -0.497 </span>
<span class="co">#&gt;  9 -0.558 </span>
<span class="co">#&gt; 10 -0.824 </span>
<span class="co">#&gt; 11  1.67  </span>
<span class="co">#&gt; 12 -0.682 </span>
<span class="co">#&gt; 13  0.0652</span>
<span class="co">#&gt; 14 -0.260 </span>
<span class="co">#&gt; 15  0.329 </span>
<span class="co">#&gt; 16 -0.437 </span>
<span class="co">#&gt; 17 -0.323 </span>
<span class="co">#&gt; 18  0.115 </span>
<span class="co">#&gt; 19  0.842 </span>
<span class="co">#&gt; 20  0.342</span></code></pre></div>
<p>Here we specified <span class="math inline">\(n=20\)</span> draws from a Normal distribution with mean of 0 and standard deviation of 1. When we deal with real data, we will not know these parameters and we want to use our data to estimate them. We can estimate the mean, <span class="math inline">\(\bar{x}\)</span>, and standard deviation, <span class="math inline">\(\hat{\sigma}_x\)</span>, with the following estimators:</p>
<p><span class="math display">\[
\begin{aligned}
\bar{x} &amp;= \frac{1}{n} \times \sum_{i = 1}^{n}x_i\\
\hat{\sigma}_{x} &amp;= \sqrt{\frac{1}{n} \times \sum_{i = 1}^{n}\left(x_i - \bar{x}\right)^2}
\end{aligned}
\]</span></p>
<p>If <span class="math inline">\(\hat{\sigma}_x\)</span> is the standard deviation, then a standard error of an estimate, say, <span class="math inline">\(\bar{x}\)</span> is:
<span class="math display">\[\mbox{SE}(\bar{x})^2 = \frac{\sigma^2}{n}\]</span></p>
<div class="sourceCode" id="cb456"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">estimated_mean</span> <span class="op">&lt;-</span>
  <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">twenty_draws_from_normal_distribution</span><span class="op">$</span><span class="va">draws</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">twenty_draws_from_normal_distribution</span><span class="op">)</span>

<span class="va">estimated_mean</span>
<span class="co">#&gt; [1] -0.2069253</span>

<span class="va">estimated_mean</span> <span class="op">&lt;-</span>
  <span class="va">twenty_draws_from_normal_distribution</span> |&gt; 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>draws_diff_square <span class="op">=</span> <span class="op">(</span><span class="va">draws</span> <span class="op">-</span> <span class="va">estimated_mean</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>

<span class="va">estimated_standard_deviation</span> <span class="op">&lt;-</span> 
  <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span>
    <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">estimated_mean</span><span class="op">$</span><span class="va">draws_diff_square</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">twenty_draws_from_normal_distribution</span><span class="op">)</span>
  <span class="op">)</span>

<span class="va">estimated_standard_deviation</span>
<span class="co">#&gt; [1] 0.8832841</span></code></pre></div>
<p>We should not be worried that our estimates are slightly off. It will typically take a larger number of draws before we get the expected shape, and our estimated parameters get close to the actual parameters, but it will happen (Figure <a href="ijalm.html#fig:normaldistributiontakingshape">14.1</a>). <span class="citation">Wasserman (<a href="references-1.html#ref-wasserman" role="doc-biblioref">2005, 76</a>)</span> describes our certainty of this, which is due to the Law of Large Numbers, as ‘a crowning achievement in probability’.</p>
<div class="sourceCode" id="cb457"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">853</span><span class="op">)</span>

<span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>
  number_of_draws <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>
    <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep.int</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"2 draws"</span>, times <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep.int</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"5 draws"</span>, times <span class="op">=</span> <span class="fl">5</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep.int</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"10 draws"</span>, times <span class="op">=</span> <span class="fl">10</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep.int</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"50 draws"</span>, times <span class="op">=</span> <span class="fl">50</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep.int</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"100 draws"</span>, times <span class="op">=</span> <span class="fl">100</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep.int</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"500 draws"</span>, times <span class="op">=</span> <span class="fl">500</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep.int</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"1,000 draws"</span>, times <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep.int</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"10,000 draws"</span>, times <span class="op">=</span> <span class="fl">10000</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep.int</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"100,000 draws"</span>, times <span class="op">=</span> <span class="fl">100000</span><span class="op">)</span>
  <span class="op">)</span>,
  draws <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>
    <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">2</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">5</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">50</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">100</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">500</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1000</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10000</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">100000</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
  <span class="op">)</span>
<span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>number_of_draws <span class="op">=</span> <span class="fu"><a href="https://forcats.tidyverse.org/reference/as_factor.html">as_factor</a></span><span class="op">(</span><span class="va">number_of_draws</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">draws</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_density.html">geom_density</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/vars.html">vars</a></span><span class="op">(</span><span class="va">number_of_draws</span><span class="op">)</span>,
             scales <span class="op">=</span> <span class="st">"free_y"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">'Draw'</span>,
       y <span class="op">=</span> <span class="st">'Density'</span><span class="op">)</span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:normaldistributiontakingshape"></span>
<img src="41-ijalm_files/figure-html/normaldistributiontakingshape-1.png" alt="The Normal distribution takes its familiar shape as the number of draws increases" width="672"><p class="caption">
Figure 14.1: The Normal distribution takes its familiar shape as the number of draws increases
</p>
</div>
<p>When we use simple linear regression, we assume that our relationship is characterized by the variables and the parameters. If we have two variables, <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>, then we could characterize a linear relationship between these as:
<span class="math display">\[Y \approx \beta_0 + \beta_1 X.\]</span></p>
<p>There are two coefficients, also ‘parameters’: the ‘intercept’, <span class="math inline">\(\beta_0\)</span>, and the ‘slope’, <span class="math inline">\(\beta_1\)</span>. We are saying that <span class="math inline">\(Y\)</span> will have some value, <span class="math inline">\(\beta_0\)</span>, even when <span class="math inline">\(X\)</span> is 0, and that <span class="math inline">\(Y\)</span> will change by <span class="math inline">\(\beta_1\)</span> units for every one unit change in <span class="math inline">\(X\)</span>. The language that we use is that ‘X is being regressed on Y’. We may then take this relationship to the data that we have, in order to estimate these coefficients, for the particular data that we have.</p>
<p>To make this example concrete, we will simulate some data and then discuss it in that context. For instance, we could consider the time it takes someone to run five kilometers, compared with the time it takes them to run a marathon (Figure <a href="ijalm.html#fig:fivekmvsmarathon">14.2</a>). We impute a relationship of 8.4, as that is roughly the ratio between the distance of a marathon and a five-kilometer race.</p>
<div class="sourceCode" id="cb458"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">853</span><span class="op">)</span>

<span class="va">number_of_observations</span> <span class="op">&lt;-</span> <span class="fl">100</span>
<span class="va">expected_relationship</span> <span class="op">&lt;-</span> <span class="fl">8.4</span>

<span class="va">simulated_running_data</span> <span class="op">&lt;-</span> 
  <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>five_km_time <span class="op">=</span> 
           <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">number_of_observations</span>, 
                 min <span class="op">=</span> <span class="fl">15</span>, 
                 max <span class="op">=</span> <span class="fl">30</span><span class="op">)</span>,
         noise <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">number_of_observations</span>, <span class="fl">0</span>, <span class="fl">20</span><span class="op">)</span>,
         marathon_time <span class="op">=</span> <span class="va">five_km_time</span> <span class="op">*</span> <span class="va">expected_relationship</span> <span class="op">+</span> <span class="va">noise</span>
         <span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>five_km_time <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">five_km_time</span>, digits <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,
         marathon_time <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">marathon_time</span>, digits <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">noise</span><span class="op">)</span>

<span class="va">simulated_running_data</span>
<span class="co">#&gt; # A tibble: 100 × 2</span>
<span class="co">#&gt;    five_km_time marathon_time</span>
<span class="co">#&gt;           &lt;dbl&gt;         &lt;dbl&gt;</span>
<span class="co">#&gt;  1         20.4          152.</span>
<span class="co">#&gt;  2         16.8          134.</span>
<span class="co">#&gt;  3         22.3          198.</span>
<span class="co">#&gt;  4         19.7          166.</span>
<span class="co">#&gt;  5         15.6          163.</span>
<span class="co">#&gt;  6         21.1          168.</span>
<span class="co">#&gt;  7         17            131.</span>
<span class="co">#&gt;  8         18.6          150.</span>
<span class="co">#&gt;  9         17.4          158.</span>
<span class="co">#&gt; 10         17.8          147.</span>
<span class="co">#&gt; # … with 90 more rows</span></code></pre></div>
<div class="sourceCode" id="cb459"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">simulated_running_data</span> |&gt; 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">five_km_time</span>, y <span class="op">=</span> <span class="va">marathon_time</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Five-kilometer time (minutes)"</span>,
       y <span class="op">=</span> <span class="st">"Marathon time (minutes)"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:fivekmvsmarathon"></span>
<img src="41-ijalm_files/figure-html/fivekmvsmarathon-1.png" alt="Simulated data of the relationship between the time to run five kilometers and a marathon" width="672"><p class="caption">
Figure 14.2: Simulated data of the relationship between the time to run five kilometers and a marathon
</p>
</div>
<p>In this simulated example, we know what <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are. But our challenge is to see if we can use only the data, and simple linear regression, to recover them. That is, can we use <span class="math inline">\(x\)</span>, which is the five-kilometer time, to produce estimates of <span class="math inline">\(y\)</span>, which is the marathon time, and which we will put a hat on to denote our estimate:</p>
<p><span class="math display">\[\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 x.\]</span>
The hats are used to indicate that these are estimated values.</p>
<p>This involves estimating values for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, and again, our estimates will be denoted by a hat on them. But how should we estimate these coefficients? Even if we impose a linear relationship there are many options, because a large number of straight lines could be drawn. But some of those lines would fit the data better than others.</p>
<p>One way we may define a line as being ‘better’ than another, is if it is as close as possible to each of the <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> combinations that we know. There are a lot of candidates for how we define ‘as close as possible’, but one is to minimize the residual sum of squares. To do this we produce estimates for <span class="math inline">\(\hat{y}\)</span> based on some guesses of <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span>, given the <span class="math inline">\(x\)</span>. We then work out how ‘wrong’, for every point <span class="math inline">\(i\)</span>, we were:
<span class="math display">\[e_i = y_i - \hat{y}_i.\]</span></p>
<p>To compute the residual sum of squares (RSS), we sum across all the points, taking the square to account for negative differences:
<span class="math display">\[\mbox{RSS} = e^2_1+ e^2_2 +\dots + e^2_n.\]</span>
This results in one ‘linear best-fit’ line (Figure <a href="ijalm.html#fig:fivekmvsmarathonwithbestfit">14.3</a>), but it is worth thinking about all the assumptions and decisions that it took to get us to this point.</p>
<div class="sourceCode" id="cb460"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">simulated_running_data</span> |&gt; 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">five_km_time</span>, y <span class="op">=</span> <span class="va">marathon_time</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, 
              se <span class="op">=</span> <span class="cn">FALSE</span>, 
              color <span class="op">=</span> <span class="st">"black"</span>, 
              linetype <span class="op">=</span> <span class="st">"dashed"</span>,
              formula <span class="op">=</span> <span class="st">'y ~ x'</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Five-kilometer time (minutes)"</span>,
       y <span class="op">=</span> <span class="st">"Marathon time (minutes)"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:fivekmvsmarathonwithbestfit"></span>
<img src="41-ijalm_files/figure-html/fivekmvsmarathonwithbestfit-1.png" alt="Simulated data of the relationship between the time to run five kilometers and a marathon" width="672"><p class="caption">
Figure 14.3: Simulated data of the relationship between the time to run five kilometers and a marathon
</p>
</div>
<p>Underpinning our use of simple linear regression is a belief that there is some ‘true’ relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, that is:</p>
<p><span class="math display">\[Y = f(X) + \epsilon.\]</span></p>
<p>We are going to say that function, <span class="math inline">\(f()\)</span>, is linear, and so for simple linear regression:</p>
<p><span class="math display">\[\hat{Y} = \beta_0 + \beta_1 X + \epsilon.\]</span></p>
<p>There is some ‘true’ relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, but we do not know what it is. All we can do is use our sample of data to estimate it. But because our understanding depends on that sample, for every possible sample, we would get a slightly different relationship, as measured by the coefficients.</p>
<p>That <span class="math inline">\(\epsilon\)</span> is a measure of our error—what does the model not know? There is going to be plenty that the model does not know, but we hope the error does not depend on <span class="math inline">\(X\)</span>, and that the error is normally distributed.</p>
<p>We can conduct simple linear regression with <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> from base R. We specify the dependent variable first, then <code>~</code>, followed by the independent variables. Finally, we specify the dataset.</p>
<div class="sourceCode" id="cb461"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">simulated_running_data_first_model</span> <span class="op">&lt;-</span> 
  <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">marathon_time</span> <span class="op">~</span> <span class="va">five_km_time</span>, 
     data <span class="op">=</span> <span class="va">simulated_running_data</span><span class="op">)</span></code></pre></div>
<p>To see the result of the regression, we can use <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> from base R.</p>
<div class="sourceCode" id="cb462"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">simulated_running_data_first_model</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = marathon_time ~ five_km_time, data = simulated_running_data)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;     Min      1Q  Median      3Q     Max </span>
<span class="co">#&gt; -49.654  -9.278   0.781  12.606  56.898 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)    8.2393     8.9550    0.92     0.36    </span>
<span class="co">#&gt; five_km_time   7.9407     0.4072   19.50   &lt;2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  </span>
<span class="co">#&gt; 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 16.96 on 98 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  0.7951, Adjusted R-squared:  0.793 </span>
<span class="co">#&gt; F-statistic: 380.3 on 1 and 98 DF,  p-value: &lt; 2.2e-16</span></code></pre></div>
<p>The first part of the result tells us the regression that we specified, then information about the residuals, and our estimated coefficients. And then finally some useful diagnostics.</p>
<p>The intercept is the marathon time that we would expect with a five-kilometer time of 0 minutes. Hopefully this example illustrates the need to carefully interpret the intercept coefficient! The coefficient on five-kilometer run time shows how we expect the marathon time to change if the five-kilometer run time changed by one unit. In this case it is about 8.4, which makes sense seeing as a marathon is roughly that many times longer than a five-kilometer run.</p>
<p>We use <code><a href="https://generics.r-lib.org/reference/augment.html">augment()</a></code> from <code>broom</code> <span class="citation">(<a href="references-1.html#ref-broom" role="doc-biblioref">D. Robinson, Hayes, and Couch 2021</a>)</span> to add the fitted values and residuals to our original dataset. This allows us to plot the residuals (Figure <a href="ijalm.html#fig:fivekmvsmarathonresids">14.4</a>).</p>
<div class="sourceCode" id="cb463"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://broom.tidymodels.org/">broom</a></span><span class="op">)</span>

<span class="va">simulated_running_data</span> <span class="op">&lt;-</span> 
  <span class="fu"><a href="https://generics.r-lib.org/reference/augment.html">augment</a></span><span class="op">(</span><span class="va">simulated_running_data_first_model</span>,
          data <span class="op">=</span> <span class="va">simulated_running_data</span><span class="op">)</span>

<span class="va">simulated_running_data</span>
<span class="co">#&gt; # A tibble: 100 × 8</span>
<span class="co">#&gt;    five_km_time marathon_time .fitted .resid   .hat .sigma</span>
<span class="co">#&gt;           &lt;dbl&gt;         &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;</span>
<span class="co">#&gt;  1         20.4          152.    170. -17.8  0.0108   17.0</span>
<span class="co">#&gt;  2         16.8          134.    142.  -7.84 0.0232   17.0</span>
<span class="co">#&gt;  3         22.3          198.    185.  13.1  0.0103   17.0</span>
<span class="co">#&gt;  4         19.7          166.    165.   1.83 0.0121   17.1</span>
<span class="co">#&gt;  5         15.6          163.    132.  31.3  0.0307   16.7</span>
<span class="co">#&gt;  6         21.1          168.    176.  -8.09 0.0101   17.0</span>
<span class="co">#&gt;  7         17            131.    143. -11.8  0.0222   17.0</span>
<span class="co">#&gt;  8         18.6          150.    156.  -6.04 0.0152   17.0</span>
<span class="co">#&gt;  9         17.4          158.    146.  11.1  0.0201   17.0</span>
<span class="co">#&gt; 10         17.8          147.    150.  -2.68 0.0183   17.0</span>
<span class="co">#&gt; # … with 90 more rows, and 2 more variables: .cooksd &lt;dbl&gt;,</span>
<span class="co">#&gt; #   .std.resid &lt;dbl&gt;</span></code></pre></div>
<div class="sourceCode" id="cb464"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">simulated_running_data</span>, 
       <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">.resid</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span>binwidth <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>y <span class="op">=</span> <span class="st">"Number of occurrences"</span>,
       x <span class="op">=</span> <span class="st">"Residuals"</span><span class="op">)</span>

<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">simulated_running_data</span>, 
       <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">five_km_time</span>, y <span class="op">=</span> <span class="va">.resid</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_hline</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fl">0</span>, linetype <span class="op">=</span> <span class="st">"dotted"</span>, color <span class="op">=</span> <span class="st">"grey"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>y <span class="op">=</span> <span class="st">"Residuals"</span>,
       x <span class="op">=</span> <span class="st">"Five-kilometer time (minutes)"</span><span class="op">)</span>

<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">simulated_running_data</span>, 
       <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">marathon_time</span>, <span class="va">.fitted</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>y <span class="op">=</span> <span class="st">"Estimated marathon time"</span>,
       x <span class="op">=</span> <span class="st">"Actual marathon time"</span><span class="op">)</span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:fivekmvsmarathonresids"></span>
<img src="41-ijalm_files/figure-html/fivekmvsmarathonresids-1.png" alt="Residuals from the simple linear regression with simulated data on the time someone takes to run five kilometers and a marathon" width="49%"><img src="41-ijalm_files/figure-html/fivekmvsmarathonresids-2.png" alt="Residuals from the simple linear regression with simulated data on the time someone takes to run five kilometers and a marathon" width="49%"><img src="41-ijalm_files/figure-html/fivekmvsmarathonresids-3.png" alt="Residuals from the simple linear regression with simulated data on the time someone takes to run five kilometers and a marathon" width="49%"><p class="caption">
Figure 14.4: Residuals from the simple linear regression with simulated data on the time someone takes to run five kilometers and a marathon
</p>
</div>
<p>We want our estimate to be unbiased. When we say our estimate is unbiased, we are trying to say that even though with some sample our estimate might be too high, and with another sample our estimate might be too low, eventually if we have a lot of data then our estimate would be the same as the population. An estimator is unbiased if it does not systematically over- or under-estimate <span class="citation">(<a href="references-1.html#ref-islr" role="doc-biblioref">James et al. 2017, 65</a>)</span>.</p>
<p>But we want to try to speak to the ‘true’ relationship, so we need to try to capture how much we think our understanding depends on the particular sample that we have to analyze. And this is where standard error comes in. It tells us how off our estimate is compared with the actual (Figure <a href="ijalm.html#fig:fivekmvsmarathonses">14.5</a>).</p>
<div class="sourceCode" id="cb465"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">simulated_running_data</span> |&gt; 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">five_km_time</span>, y <span class="op">=</span> <span class="va">marathon_time</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, 
              se <span class="op">=</span> <span class="cn">TRUE</span>, 
              color <span class="op">=</span> <span class="st">"black"</span>, 
              linetype <span class="op">=</span> <span class="st">"dashed"</span>,
              formula <span class="op">=</span> <span class="st">'y ~ x'</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Five-kilometer time (minutes)"</span>,
       y <span class="op">=</span> <span class="st">"Marathon time (minutes)"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:fivekmvsmarathonses"></span>
<img src="41-ijalm_files/figure-html/fivekmvsmarathonses-1.png" alt="Simple linear regression with simulated data on the time someone takes to run five kilometers and a marathon, along with standard errors" width="672"><p class="caption">
Figure 14.5: Simple linear regression with simulated data on the time someone takes to run five kilometers and a marathon, along with standard errors
</p>
</div>
<p>From standard errors, we can compute a confidence interval. A 95 per cent confidence interval is a range, such that there is roughly a 0.95 probability that the interval happens to contain the population parameter, which is typically unknown. The lower end of this range is: <span class="math inline">\(\hat{\beta_1} - 2 \times \mbox{SE}\left(\hat{\beta_1}\right)\)</span> and the upper end of this range is: <span class="math inline">\(\hat{\beta_1} + 2 \times \mbox{SE}\left(\hat{\beta_1}\right)\)</span>.</p>
<p>Now that we have a range, for which we can say there is a roughly 95 per cent probability that range contains the true population parameter, we could test claims. For instance, we could claim that there is no relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, i.e. <span class="math inline">\(\beta_1 = 0\)</span>, as an alternative to a claim that there is some relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, i.e. <span class="math inline">\(\beta_1 \neq 0\)</span>.</p>
<p>In the same way that in Chapter <a href="hunt-data.html#hunt-data">10</a> we needed to decide how much evidence it would take to convince us that our tea taster could distinguish whether milk or tea had been added first, we need to decide whether our estimate of <span class="math inline">\(\beta_1\)</span>, which is <span class="math inline">\(\hat{\beta}_1\)</span>, is ‘far enough’ away from zero for us to be comfortable claiming that <span class="math inline">\(\beta_1 \neq 0\)</span>. How far is ‘far enough’? If we were very confident in our estimate of <span class="math inline">\(\beta_1\)</span> then it would not have to be far, but if we were not then it would have to be substantial. The standard error of <span class="math inline">\(\hat{\beta}_1\)</span> does an awful lot of work here in accounting for a variety of factors, only some of which it can actually account for.</p>
<p>We compare this standard error with <span class="math inline">\(\hat{\beta}_1\)</span> to get the t-statistic:
<span class="math display">\[t = \frac{\hat{\beta}_1 - 0}{\mbox{SE}(\hat{\beta}_1)}.\]</span>
And we then compare our t-statistic to the t-distribution to compute the probability of getting this absolute t-statistic or a larger one, if it was actually the case that <span class="math inline">\(\beta_1 = 0\)</span>. This probability is the p-value. A smaller p-value means it is less likely that we would observe our data due to chance if there was not a relationship.</p>
<blockquote>
<p>Words! Mere words! How terrible they were! How clear, and vivid, and cruel! One could not escape from them. And yet what a subtle magic there was in them! They seemed to be able to give a plastic form to formless things, and to have a music of their own as sweet as that of viol or of lute. Mere words! Was there anything so real as words?</p>
<p><em>The Picture of Dorian Gray</em> <span class="citation">(<a href="references-1.html#ref-wilde" role="doc-biblioref">Wilde 1891</a>)</span>.</p>
</blockquote>
<p>We will not make much use of p-values in this book because they are a specific and subtle concept. They are difficult to understand and easy to abuse. The main issue is that they embody, and assume correct, every assumption of the model, including everything that went into gathering and cleaning the data. While smaller p-values do imply the data are more unusual if all the assumptions were correct; when we consider the full data science workflow there are usually an awful lot of assumptions. And we do not get guidance from p-values about the reasonableness of specific assumptions <span class="citation">(<a href="references-1.html#ref-greenland2016statistical" role="doc-biblioref">Greenland et al. 2016, 339</a>)</span>. A p-value may reject a null hypothesis because the null hypothesis is actually false, but it may also be that some data were incorrectly gathered or prepared. We can only be sure that the p-value speaks to the hypothesis we are interested in testing, if all the other assumptions are correct. There is nothing inherently wrong about using p-values, but it is important to use them in sophisticated and thoughtful ways. <span class="citation">D. Cox (<a href="references-1.html#ref-coxtalks" role="doc-biblioref">2018</a>)</span> provides a lovely discussion of what this requires.</p>
<p>One application where it is easy to see abuse of p-values is in power analysis. Power, in a statistical sense, refers to probability of rejecting a null hypothesis that is actually false. As power relates to hypothesis testing, it also related to sample size. There is often a worry that a study is ‘under-powered’, meaning there was not a large enough sample, but rarely a worry that, say, the data were inappropriately cleaned, even though we cannot distinguish between these based only on a p-value.</p>
</div>
<div id="multiple-linear-regression" class="section level2" number="14.3">
<h2>
<span class="header-section-number">14.3</span> Multiple linear regression<a class="anchor" aria-label="anchor" href="#multiple-linear-regression"><i class="fas fa-link"></i></a>
</h2>
<p>To this point we have just considered one explanatory variable. But we will usually have more than one. One approach would be to run separate regressions for each explanatory variable. But compared with separate linear regressions for each, adding more explanatory variables allows us to have a better understanding of the intercept and accounts for interaction. Often the results will be quite different.</p>
<p>We may also like to consider explanatory variables that do not have an inherent ordering. For instance: pregnant or not; day or night. When there are only two options then we can use a binary variable, which is considered either 0 or 1. If we have a column of character values that only has two values, such as: <code>c("Myles", "Ruth", "Ruth", "Myles", "Myles", "Ruth")</code>, then using this as an explanatory variable in the usual regression set up, would mean that it is treated as a binary variable. If there are more than two levels then we can use a combination of binary variables, where the ‘missing’ outcome (baseline) gets pushed into the intercept.</p>
<div class="sourceCode" id="cb466"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">simulated_running_data</span> <span class="op">&lt;-</span>
  <span class="va">simulated_running_data</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>was_raining <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span>
    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Yes"</span>, <span class="st">"No"</span><span class="op">)</span>,
    size <span class="op">=</span> <span class="va">number_of_observations</span>,
    replace <span class="op">=</span> <span class="cn">TRUE</span>,
    prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="fl">0.8</span><span class="op">)</span>
  <span class="op">)</span><span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">five_km_time</span>, <span class="va">marathon_time</span>, <span class="va">was_raining</span><span class="op">)</span>

<span class="va">simulated_running_data</span>
<span class="co">#&gt; # A tibble: 100 × 3</span>
<span class="co">#&gt;    five_km_time marathon_time was_raining</span>
<span class="co">#&gt;           &lt;dbl&gt;         &lt;dbl&gt; &lt;chr&gt;      </span>
<span class="co">#&gt;  1         20.4          152. No         </span>
<span class="co">#&gt;  2         16.8          134. No         </span>
<span class="co">#&gt;  3         22.3          198. No         </span>
<span class="co">#&gt;  4         19.7          166. No         </span>
<span class="co">#&gt;  5         15.6          163. No         </span>
<span class="co">#&gt;  6         21.1          168. No         </span>
<span class="co">#&gt;  7         17            131. No         </span>
<span class="co">#&gt;  8         18.6          150. No         </span>
<span class="co">#&gt;  9         17.4          158. No         </span>
<span class="co">#&gt; 10         17.8          147. No         </span>
<span class="co">#&gt; # … with 90 more rows</span></code></pre></div>
<p>We can add additional explanatory variables to <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> with <code>+</code>.</p>
<div class="sourceCode" id="cb467"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">simulated_running_data_rain_model</span> <span class="op">&lt;-</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">marathon_time</span> <span class="op">~</span> <span class="va">five_km_time</span> <span class="op">+</span> <span class="va">was_raining</span>,
     data <span class="op">=</span> <span class="va">simulated_running_data</span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">simulated_running_data_rain_model</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = marathon_time ~ five_km_time + was_raining, data = simulated_running_data)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;     Min      1Q  Median      3Q     Max </span>
<span class="co">#&gt; -49.150  -8.828   0.968  10.522  58.224 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;                Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)      9.1030     9.0101   1.010    0.315    </span>
<span class="co">#&gt; five_km_time     7.8660     0.4154  18.934   &lt;2e-16 ***</span>
<span class="co">#&gt; was_rainingYes   4.1673     4.5048   0.925    0.357    </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  </span>
<span class="co">#&gt; 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 16.98 on 97 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  0.7969, Adjusted R-squared:  0.7927 </span>
<span class="co">#&gt; F-statistic: 190.3 on 2 and 97 DF,  p-value: &lt; 2.2e-16</span></code></pre></div>
<p>The result probably is not too surprising if we look at a plot of the data (Figure <a href="ijalm.html#fig:fivekmvsmarathonbinary">14.6</a>).</p>
<div class="sourceCode" id="cb468"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">simulated_running_data</span> |&gt;
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">five_km_time</span>, y <span class="op">=</span> <span class="va">marathon_time</span>, color <span class="op">=</span> <span class="va">was_raining</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>,
              color <span class="op">=</span> <span class="st">"black"</span>, 
              linetype <span class="op">=</span> <span class="st">"dashed"</span>,
              formula <span class="op">=</span> <span class="st">'y ~ x'</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Five-kilometer time (minutes)"</span>,
       y <span class="op">=</span> <span class="st">"Marathon time (minutes)"</span>,
       color <span class="op">=</span> <span class="st">"Was raining"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_brewer.html">scale_color_brewer</a></span><span class="op">(</span>palette <span class="op">=</span> <span class="st">"Set1"</span><span class="op">)</span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:fivekmvsmarathonbinary"></span>
<img src="41-ijalm_files/figure-html/fivekmvsmarathonbinary-1.png" alt="Simple linear regression with simulated data on the time someone takes to run five kilometers and a marathon, with a binary variable for whether it was raining" width="672"><p class="caption">
Figure 14.6: Simple linear regression with simulated data on the time someone takes to run five kilometers and a marathon, with a binary variable for whether it was raining
</p>
</div>
<p>In addition to wanting to include additional explanatory variables, we may think that they are related with each another. For instance, if we were wanting to explain the amount of snowfall, then we may be interested in the humidity and the temperature, but those two variables may also interact. We can do this by using <code>*</code> instead of <code>+</code> when we specify the model. When we interact variables in this way, then we almost always need to include the individual variables as well and <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> will do this by default.</p>
<div class="sourceCode" id="cb469"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">simulated_running_data</span> <span class="op">&lt;-</span>
  <span class="va">simulated_running_data</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>humidity <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span>
    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"High"</span>, <span class="st">"Low"</span><span class="op">)</span>,
    size <span class="op">=</span> <span class="va">number_of_observations</span>,
    replace <span class="op">=</span> <span class="cn">TRUE</span>,
    prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="fl">0.8</span><span class="op">)</span>
  <span class="op">)</span><span class="op">)</span>

<span class="va">simulated_running_data</span>
<span class="co">#&gt; # A tibble: 100 × 4</span>
<span class="co">#&gt;    five_km_time marathon_time was_raining humidity</span>
<span class="co">#&gt;           &lt;dbl&gt;         &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;   </span>
<span class="co">#&gt;  1         20.4          152. No          Low     </span>
<span class="co">#&gt;  2         16.8          134. No          Low     </span>
<span class="co">#&gt;  3         22.3          198. No          Low     </span>
<span class="co">#&gt;  4         19.7          166. No          Low     </span>
<span class="co">#&gt;  5         15.6          163. No          Low     </span>
<span class="co">#&gt;  6         21.1          168. No          Low     </span>
<span class="co">#&gt;  7         17            131. No          Low     </span>
<span class="co">#&gt;  8         18.6          150. No          Low     </span>
<span class="co">#&gt;  9         17.4          158. No          High    </span>
<span class="co">#&gt; 10         17.8          147. No          Low     </span>
<span class="co">#&gt; # … with 90 more rows</span></code></pre></div>
<div class="sourceCode" id="cb470"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">simulated_running_data_rain_and_humidity_model</span> <span class="op">&lt;-</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">marathon_time</span> <span class="op">~</span> <span class="va">five_km_time</span> <span class="op">+</span> <span class="va">was_raining</span><span class="op">*</span><span class="va">humidity</span>,
     data <span class="op">=</span> <span class="va">simulated_running_data</span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">simulated_running_data_rain_and_humidity_model</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = marathon_time ~ five_km_time + was_raining * humidity, </span>
<span class="co">#&gt;     data = simulated_running_data)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;     Min      1Q  Median      3Q     Max </span>
<span class="co">#&gt; -48.904  -8.523   0.404  10.130  59.951 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;                            Estimate Std. Error t value</span>
<span class="co">#&gt; (Intercept)                 15.0595    10.3144   1.460</span>
<span class="co">#&gt; five_km_time                 7.7313     0.4167  18.552</span>
<span class="co">#&gt; was_rainingYes              15.6008     9.6199   1.622</span>
<span class="co">#&gt; humidityLow                 -3.7380     4.9569  -0.754</span>
<span class="co">#&gt; was_rainingYes:humidityLow -14.5825    10.7410  -1.358</span>
<span class="co">#&gt;                            Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)                   0.148    </span>
<span class="co">#&gt; five_km_time                 &lt;2e-16 ***</span>
<span class="co">#&gt; was_rainingYes                0.108    </span>
<span class="co">#&gt; humidityLow                   0.453    </span>
<span class="co">#&gt; was_rainingYes:humidityLow    0.178    </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  </span>
<span class="co">#&gt; 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 16.79 on 95 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  0.8054, Adjusted R-squared:  0.7972 </span>
<span class="co">#&gt; F-statistic: 98.31 on 4 and 95 DF,  p-value: &lt; 2.2e-16</span></code></pre></div>
<p>There are a variety of threats to the validity of linear regression estimates, and aspects to think about. We need to address these when we use it, and usually four graphs and associated text are sufficient to assuage most of these. Aspects of concern include:</p>
<ol style="list-style-type: decimal">
<li>Linearity of explanatory variables. We are concerned with whether the independent variables enter in a linear way. Sometimes if we are worried that there might be a multiplicative relationship between the explanatory variables, rather than an additive one, then we may consider a logarithmic transform. We can usually be convinced there is enough linearity in our explanatory variables for our purposes by using graphs of the variables.</li>
<li>Independence of errors. We are concerned that the errors are not correlated. For instance, if we are interested in weather-related measurement such as average daily temperature, then we may find a pattern because the temperature on one day is likely similar to the temperature on another. We can be convinced that we have satisfied this condition by making graphs of the errors, such as Figure <a href="ijalm.html#fig:fivekmvsmarathonresids">14.4</a>.</li>
<li>Homoscedasticity of errors. We are concerned that the errors are not becoming systematically larger or smaller throughout the sample. If that is happening, then we term it heteroscedasticity. Again, graphs of errors, such as Figure <a href="ijalm.html#fig:fivekmvsmarathonresids">14.4</a> are used to convince us of this.</li>
<li>Normality of errors. We are concerned that our errors are normally distributed when we are interested in making individual-level predictions.</li>
<li>Outliers and other high-impact observations. Finally, we might be worried that our results are being driven by a handful of observations. For instance, thinking back to Chapter <a href="static-communication.html#static-communication">6</a> and Anscombe’s Quartet, we notice that linear regression estimates would be heavily influenced by the inclusion of one or two particular points. We can become comfortable with this by considering our analysis on various sub-sets</li>
</ol>
<p>Those aspects are statistical concerns and relate to whether the model is working. The most important threat to validity and hence the aspect that must be addressed at some length, is speaking to the fact that this model is appropriate to the circumstances and addresses the research question at hand.</p>
<p>To this point, we have just had a quick look at the regression results using <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code>. A better approach is to use <code><a href="https://vincentarelbundock.github.io/modelsummary/reference/modelsummary.html">modelsummary()</a></code> from <code>modelsummary</code> <span class="citation">(<a href="references-1.html#ref-citemodelsummary" role="doc-biblioref">Arel-Bundock 2021a</a>)</span> (Table <a href="ijalm.html#tab:modelsummaryruntimes">14.1</a>).</p>
<div class="sourceCode" id="cb471"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://vincentarelbundock.github.io/modelsummary/">modelsummary</a></span><span class="op">)</span>

<span class="fu"><a href="https://vincentarelbundock.github.io/modelsummary/reference/modelsummary.html">modelsummary</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">simulated_running_data_first_model</span>,
                  <span class="va">simulated_running_data_rain_model</span>, 
                  <span class="va">simulated_running_data_rain_and_humidity_model</span><span class="op">)</span>,
             fmt <span class="op">=</span> <span class="fl">2</span>,
             title <span class="op">=</span> <span class="st">"Explaining marathon time based on five-kilometer run times and weather features"</span><span class="op">)</span></code></pre></div>
<div class="inline-table"><table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:modelsummaryruntimes">Table 14.1: </span>Explaining marathon time based on five-kilometer run times and weather features
</caption>
<thead><tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
Model 1
</th>
<th style="text-align:center;">
Model 2
</th>
<th style="text-align:center;">
Model 3
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:center;">
8.24
</td>
<td style="text-align:center;">
9.10
</td>
<td style="text-align:center;">
15.06
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
(8.96)
</td>
<td style="text-align:center;">
(9.01)
</td>
<td style="text-align:center;">
(10.31)
</td>
</tr>
<tr>
<td style="text-align:left;">
five_km_time
</td>
<td style="text-align:center;">
7.94
</td>
<td style="text-align:center;">
7.87
</td>
<td style="text-align:center;">
7.73
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
(0.41)
</td>
<td style="text-align:center;">
(0.42)
</td>
<td style="text-align:center;">
(0.42)
</td>
</tr>
<tr>
<td style="text-align:left;">
was_rainingYes
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
4.17
</td>
<td style="text-align:center;">
15.60
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
(4.50)
</td>
<td style="text-align:center;">
(9.62)
</td>
</tr>
<tr>
<td style="text-align:left;">
humidityLow
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
−3.74
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
(4.96)
</td>
</tr>
<tr>
<td style="text-align:left;">
was_rainingYes × humidityLow
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
−14.58
</td>
</tr>
<tr>
<td style="text-align:left;box-shadow: 0px 1px">
</td>
<td style="text-align:center;box-shadow: 0px 1px">
</td>
<td style="text-align:center;box-shadow: 0px 1px">
</td>
<td style="text-align:center;box-shadow: 0px 1px">
(10.74)
</td>
</tr>
<tr>
<td style="text-align:left;">
Num.Obs.
</td>
<td style="text-align:center;">
100
</td>
<td style="text-align:center;">
100
</td>
<td style="text-align:center;">
100
</td>
</tr>
<tr>
<td style="text-align:left;">
R2
</td>
<td style="text-align:center;">
0.795
</td>
<td style="text-align:center;">
0.797
</td>
<td style="text-align:center;">
0.805
</td>
</tr>
<tr>
<td style="text-align:left;">
R2 Adj.
</td>
<td style="text-align:center;">
0.793
</td>
<td style="text-align:center;">
0.793
</td>
<td style="text-align:center;">
0.797
</td>
</tr>
<tr>
<td style="text-align:left;">
AIC
</td>
<td style="text-align:center;">
854.0
</td>
<td style="text-align:center;">
855.1
</td>
<td style="text-align:center;">
854.8
</td>
</tr>
<tr>
<td style="text-align:left;">
BIC
</td>
<td style="text-align:center;">
861.8
</td>
<td style="text-align:center;">
865.5
</td>
<td style="text-align:center;">
870.4
</td>
</tr>
<tr>
<td style="text-align:left;">
Log.Lik.
</td>
<td style="text-align:center;">
−423.993
</td>
<td style="text-align:center;">
−423.554
</td>
<td style="text-align:center;">
−421.405
</td>
</tr>
<tr>
<td style="text-align:left;">
F
</td>
<td style="text-align:center;">
380.262
</td>
<td style="text-align:center;">
190.279
</td>
<td style="text-align:center;">
98.314
</td>
</tr>
</tbody>
</table></div>
<p>When we are focused on prediction, we will often want to fit many models. One way to do this is to copy and paste code many times. There is nothing wrong with that. And that is the way that most people get started. But we need an approach that:</p>
<ol style="list-style-type: decimal">
<li>scales more easily;</li>
<li>enables us to think carefully about over-fitting; and</li>
<li>adds model evaluation.</li>
</ol>
<p>The use of <code>tidymodels</code> <span class="citation">(<a href="references-1.html#ref-citeTidymodels" role="doc-biblioref">Kuhn and Wickham 2020</a>)</span> satisfies these criteria by providing a coherent grammar that allows us to easily fit a variety of models. Like <code>tidyverse</code>, it is a package of packages.</p>
<p>As we are focused on prediction, we are worried about over-fitting our data, which would limit our ability to make claims about other datasets. One way to partially address this is to split our dataset into training and test datasets using <code>initial_split()</code>.</p>
<div class="sourceCode" id="cb472"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidymodels.tidymodels.org">tidymodels</a></span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">853</span><span class="op">)</span>

<span class="va">simulated_running_data_split</span> <span class="op">&lt;-</span> 
  <span class="fu">initial_split</span><span class="op">(</span>data <span class="op">=</span> <span class="va">simulated_running_data</span>, 
                prop <span class="op">=</span> <span class="fl">0.80</span><span class="op">)</span>

<span class="va">simulated_running_data_split</span>
<span class="co">#&gt; &lt;Analysis/Assess/Total&gt;</span>
<span class="co">#&gt; &lt;80/20/100&gt;</span></code></pre></div>
<p>Having split the data, we then create the training and test datasets.</p>
<div class="sourceCode" id="cb473"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">simulated_running_data_train</span> <span class="op">&lt;-</span> <span class="fu">training</span><span class="op">(</span><span class="va">simulated_running_data_split</span><span class="op">)</span>

<span class="va">simulated_running_data_train</span>
<span class="co">#&gt; # A tibble: 80 × 4</span>
<span class="co">#&gt;    five_km_time marathon_time was_raining humidity</span>
<span class="co">#&gt;           &lt;dbl&gt;         &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;   </span>
<span class="co">#&gt;  1         17.4          158. No          High    </span>
<span class="co">#&gt;  2         23.8          205. No          High    </span>
<span class="co">#&gt;  3         23.4          198. Yes         Low     </span>
<span class="co">#&gt;  4         22.3          175  No          Low     </span>
<span class="co">#&gt;  5         19.3          158  No          Low     </span>
<span class="co">#&gt;  6         24.4          204. No          High    </span>
<span class="co">#&gt;  7         17            120  No          High    </span>
<span class="co">#&gt;  8         19.1          178. No          Low     </span>
<span class="co">#&gt;  9         22.3          198. No          Low     </span>
<span class="co">#&gt; 10         20.6          166. No          Low     </span>
<span class="co">#&gt; # … with 70 more rows</span>

<span class="va">simulated_running_data_test</span> <span class="op">&lt;-</span> <span class="fu">testing</span><span class="op">(</span><span class="va">simulated_running_data_split</span><span class="op">)</span>

<span class="va">simulated_running_data_test</span>
<span class="co">#&gt; # A tibble: 20 × 4</span>
<span class="co">#&gt;    five_km_time marathon_time was_raining humidity</span>
<span class="co">#&gt;           &lt;dbl&gt;         &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;   </span>
<span class="co">#&gt;  1         17            131. No          Low     </span>
<span class="co">#&gt;  2         16.6          118. No          Low     </span>
<span class="co">#&gt;  3         19.6          164. No          Low     </span>
<span class="co">#&gt;  4         21.1          164. Yes         Low     </span>
<span class="co">#&gt;  5         21            180. No          Low     </span>
<span class="co">#&gt;  6         27.9          246. No          Low     </span>
<span class="co">#&gt;  7         23.7          198. No          High    </span>
<span class="co">#&gt;  8         16            143  No          Low     </span>
<span class="co">#&gt;  9         24.9          202. No          Low     </span>
<span class="co">#&gt; 10         15.2          140. Yes         Low     </span>
<span class="co">#&gt; 11         28.9          238. No          Low     </span>
<span class="co">#&gt; 12         19.2          132  Yes         Low     </span>
<span class="co">#&gt; 13         22            200. No          Low     </span>
<span class="co">#&gt; 14         26.5          229  Yes         High    </span>
<span class="co">#&gt; 15         25.3          222  Yes         High    </span>
<span class="co">#&gt; 16         25.9          208. Yes         Low     </span>
<span class="co">#&gt; 17         15.5          120  No          Low     </span>
<span class="co">#&gt; 18         18            144. No          Low     </span>
<span class="co">#&gt; 19         27.2          227. No          High    </span>
<span class="co">#&gt; 20         20.8          201. No          Low</span></code></pre></div>
<p>When we look at the training and test datasets, we can see that we have placed most of our dataset into the training dataset. We will use that to estimate the parameters of our model. We have kept a small amount of it back, and we will use that to evaluate our model.</p>
<div class="sourceCode" id="cb474"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">simulated_running_data_first_model_tidymodels</span> <span class="op">&lt;-</span> 
  <span class="fu">linear_reg</span><span class="op">(</span><span class="op">)</span> |&gt;
  <span class="fu">set_engine</span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"lm"</span><span class="op">)</span> |&gt; 
  <span class="fu">fit</span><span class="op">(</span><span class="va">marathon_time</span> <span class="op">~</span> <span class="va">five_km_time</span> <span class="op">+</span> <span class="va">was_raining</span>, 
      data <span class="op">=</span> <span class="va">simulated_running_data_train</span>
      <span class="op">)</span>

<span class="va">simulated_running_data_first_model_tidymodels</span>
<span class="co">#&gt; parsnip model object</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Fit time:  1ms </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; stats::lm(formula = marathon_time ~ five_km_time + was_raining, </span>
<span class="co">#&gt;     data = data)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;    (Intercept)    five_km_time  was_rainingYes  </span>
<span class="co">#&gt;         16.601           7.490           8.244</span></code></pre></div>
<p>We will use <code>tidymodels</code> for forecasting. But when we are focused on inference, instead, we will use Bayesian approaches. To do this we use the probabilistic programming language ‘Stan’, and interface with it using <code>rstanarm</code> <span class="citation">(<a href="references-1.html#ref-citerstanarm" role="doc-biblioref">Goodrich et al. 2020</a>)</span>. We keep these separate, rather than adapting Bayesian approaches within <code>tidymodels</code>, because to this point the ecosystems have developed separately, and so the best books to go onto next are also separate.</p>
<p>In order to use Bayesian approaches we will need to specify a starting point, or prior. This is another reason for the workflow advocated in this book; the simulate stage leads directly to priors. We will also more thoroughly specify the model that we are interested in:</p>
<p><span class="math display">\[
\begin{aligned}
y_i &amp;\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &amp;= \beta_0 +\beta_1x_i\\
\beta_0 &amp;\sim \mbox{Normal}(0, 3) \\
\beta_1 &amp;\sim \mbox{Normal}(0, 3) \\
\sigma &amp;\sim \mbox{Normal}(0, 3) \\
\end{aligned}
\]</span></p>
<p>On a practical note, one aspect that different between Bayesian approaches and the way we have been doing modelling to this point, is that Bayesian models will usually take longer to run. Because of this, it can be useful to run the model, either within the R Markdown document or in a separate R script, and then save it with <code><a href="https://rdrr.io/r/base/readRDS.html">saveRDS()</a></code>. With sensible R Markdown chunk options, the model can then be read into the R Markdown document with <code><a href="https://rdrr.io/r/base/readRDS.html">readRDS()</a></code>. In this way, the model, and hence delay, is only imposed once for a given model.</p>
<div class="sourceCode" id="cb475"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mc-stan.org/rstanarm/">rstanarm</a></span><span class="op">)</span>

<span class="va">simulated_running_data_first_model_rstanarm</span> <span class="op">&lt;-</span>
  <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_lm.html">stan_lm</a></span><span class="op">(</span>
    <span class="va">marathon_time</span> <span class="op">~</span> <span class="va">five_km_time</span> <span class="op">+</span> <span class="va">was_raining</span>, 
    data <span class="op">=</span> <span class="va">simulated_running_data</span>,
    prior <span class="op">=</span> <span class="cn">NULL</span>,
    seed <span class="op">=</span> <span class="fl">853</span>
  <span class="op">)</span>

<span class="co"># simulated_running_data_first_model_rstanarm &lt;-</span>
<span class="co">#   stan_lm(</span>
<span class="co">#     formula = marathon_time ~ five_km_time,</span>
<span class="co">#     data = simulated_running_data,</span>
<span class="co">#     prior = normal(0, 3),</span>
<span class="co">#     prior_intercept = normal(0, 3),</span>
<span class="co">#     prior_aux = normal(0, 3),</span>
<span class="co">#     seed = 853</span>
<span class="co">#     )</span>

<span class="fu"><a href="https://rdrr.io/r/base/readRDS.html">saveRDS</a></span><span class="op">(</span><span class="va">simulated_running_data_first_model_rstanarm</span>,
        file <span class="op">=</span> <span class="st">"simulated_running_data_first_model_rstanarm.rds"</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb476"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">simulated_running_data_first_model_rstanarm</span>
<span class="co">#&gt; stan_lm</span>
<span class="co">#&gt;  family:       gaussian [identity]</span>
<span class="co">#&gt;  formula:      marathon_time ~ five_km_time + was_raining</span>
<span class="co">#&gt;  observations: 100</span>
<span class="co">#&gt;  predictors:   3</span>
<span class="co">#&gt; ------</span>
<span class="co">#&gt;                Median MAD_SD</span>
<span class="co">#&gt; (Intercept)    9.2    8.7   </span>
<span class="co">#&gt; five_km_time   7.9    0.4   </span>
<span class="co">#&gt; was_rainingYes 4.6    4.5   </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Auxiliary parameter(s):</span>
<span class="co">#&gt;               Median MAD_SD</span>
<span class="co">#&gt; R2             0.8    0.0  </span>
<span class="co">#&gt; log-fit_ratio  0.0    0.0  </span>
<span class="co">#&gt; sigma         17.1    1.3  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; ------</span>
<span class="co">#&gt; * For help interpreting the printed output see ?print.stanreg</span>
<span class="co">#&gt; * For info on the priors used see ?prior_summary.stanreg</span></code></pre></div>
<!-- ## Tutorial -->
<!-- Let's do this in the context of the Paspaley dataset that we were introduced to in an earlier lecture. -->
<!-- Read in the data. -->
<!-- ```{r} -->
<!-- paspaley_data <- read_csv(here::here("notes/inputs/data/paspaley_cleaned_dataset.csv")) -->
<!-- head(paspaley_data) -->
<!-- ``` -->
<!-- Take a brief look: -->
<!-- ```{r} -->
<!-- skimr::skim(paspaley_data) -->
<!-- paspaley_data$keshi |> table() -->
<!-- paspaley_data$metal |> table() -->
<!-- paspaley_data$category |> table() -->
<!-- ``` -->
<!-- Clean up and remove some anonying other variables. -->
<!-- ```{r} -->
<!-- paspaley_data <-  -->
<!--   paspaley_data |>  -->
<!--   filter(metal != "Other") |>  -->
<!--   filter(category != "Other") -->
<!-- ``` -->
<!-- Run a ordinary linear regression. -->
<!-- ```{r} -->
<!-- model_1 <- lm(price ~ keshi, data = paspaley_data) -->
<!-- model_2 <- lm(price ~ metal, data = paspaley_data) -->
<!-- model_3 <- lm(price ~ category, data = paspaley_data) -->
<!-- model_4 <- lm(price ~ keshi + metal + category, data = paspaley_data) -->
<!-- ``` -->
<!-- `broom` is great to look at the models, in particular `glance` and `tidy`.  -->
<!-- ```{r} -->
<!-- summary(model_1) -->
<!-- broom::glance(model_1) -->
<!-- broom::tidy(model_1) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- broom::glance(model_4) -->
<!-- broom::tidy(model_4) -->
<!-- paspaley_data |>  -->
<!--   ggplot(aes(x = price)) + -->
<!--   geom_histogram() + -->
<!--   facet_wrap(vars(metal), scales = "free_y") -->
<!-- ``` -->
<!-- You can add the fitted variables easily too. -->
<!-- ```{r} -->
<!-- paspaley_data_with_model_4 <- broom::augment(model_4) -->
<!-- head(model_4) -->
<!-- ``` -->
</div>
<div id="logistic-regression" class="section level2" number="14.4">
<h2>
<span class="header-section-number">14.4</span> Logistic regression<a class="anchor" aria-label="anchor" href="#logistic-regression"><i class="fas fa-link"></i></a>
</h2>
<p>Linear regression is a nice way to come to understand better our data. But it assumes a continuous outcome variable which can take any number on the real line. We would like some way to use this same machinery when we cannot satisfy this condition. We turn to logistic and Poisson regression for binary and count outcome variables, respectively.</p>
<p>Logistic regression and its close variants are useful in a variety of settings, from elections <span class="citation">(<a href="references-1.html#ref-wang2015forecasting" role="doc-biblioref">W. Wang et al. 2015</a>)</span> through to horse racing <span class="citation">(<a href="references-1.html#ref-chellel2018gambler" role="doc-biblioref">Chellel 2018</a>; <a href="references-1.html#ref-boltonruth" role="doc-biblioref">Bolton and Chapman 1986</a>)</span>. We use logistic regression when the dependent variable is a binary outcome, such as 0 or 1. Although the presence of a binary outcome variable may sound limiting, there are a lot of circumstances in which the outcome either naturally falls into this situation, or can be adjusted into it.</p>
<p>The reason that we use logistic regression is that we will be modelling a probability and so it will be bounded between 0 and 1. Whereas with linear regression we may end up with values outside this. This all said, logistic regression, as Daniella Witten teaches us, is just a linear model. The foundation of logistic regression is the logit function:</p>
<p><span class="math display">\[
\mbox{logit}(x) = \log\left(\frac{x}{1-x}\right),
\]</span>
which will transpose values between 0 and 1, onto the real line. For instance, <code>logit(0.1) = -2.2</code>, <code>logit(0.5) = 0</code>, and <code>logit(0.9) = 2.2</code>.</p>
<p>We will simulate data on whether it is day or night, based on the number of cars that we can see.</p>
<div class="sourceCode" id="cb477"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">853</span><span class="op">)</span>

<span class="va">day_or_night</span> <span class="op">&lt;-</span> 
  <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>
    number_of_cars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1000</span>, min <span class="op">=</span> <span class="fl">0</span>, <span class="fl">100</span><span class="op">)</span>,
    noise <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1000</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>,
    is_night <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/if_else.html">if_else</a></span><span class="op">(</span><span class="va">number_of_cars</span> <span class="op">+</span> <span class="va">noise</span> <span class="op">&gt;</span> <span class="fl">50</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span>
  <span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>number_of_cars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">number_of_cars</span><span class="op">)</span><span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">noise</span><span class="op">)</span>
  
<span class="va">day_or_night</span>
<span class="co">#&gt; # A tibble: 1,000 × 2</span>
<span class="co">#&gt;    number_of_cars is_night</span>
<span class="co">#&gt;             &lt;dbl&gt;    &lt;dbl&gt;</span>
<span class="co">#&gt;  1             36        0</span>
<span class="co">#&gt;  2             12        0</span>
<span class="co">#&gt;  3             48        0</span>
<span class="co">#&gt;  4             32        0</span>
<span class="co">#&gt;  5              4        0</span>
<span class="co">#&gt;  6             40        0</span>
<span class="co">#&gt;  7             13        0</span>
<span class="co">#&gt;  8             24        0</span>
<span class="co">#&gt;  9             16        0</span>
<span class="co">#&gt; 10             19        0</span>
<span class="co">#&gt; # … with 990 more rows</span></code></pre></div>
<p>As with linear regression, logistic regression with can use <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code> from base to put together a quick model and <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> to look at it. In this case we will try to work out whether it is day or night, based on the number of cars we can see. We are interested in estimating Equation <a href="ijalm.html#eq:logisticexample">(14.1)</a>:
<span class="math display" id="eq:logisticexample">\[
\mbox{Pr}(y_i=1) = \mbox{logit}^{-1}\left(\beta_0+\beta_1 x_i\right). \tag{14.1}
\]</span></p>
<div class="sourceCode" id="cb478"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">day_or_night_model</span> <span class="op">&lt;-</span> 
  <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">is_night</span> <span class="op">~</span> <span class="va">number_of_cars</span>,
      data <span class="op">=</span> <span class="va">day_or_night</span>,
      family <span class="op">=</span> <span class="st">'binomial'</span><span class="op">)</span>
<span class="co">#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1</span>
<span class="co">#&gt; occurred</span>

<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">day_or_night_model</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = is_night ~ number_of_cars, family = "binomial", </span>
<span class="co">#&gt;     data = day_or_night)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;      Min        1Q    Median        3Q       Max  </span>
<span class="co">#&gt; -2.39419  -0.00002   0.00000   0.00002   2.33776  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;                Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)    -45.5353     7.3389  -6.205 5.48e-10 ***</span>
<span class="co">#&gt; number_of_cars   0.9121     0.1470   6.205 5.47e-10 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  </span>
<span class="co">#&gt; 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 1386.194  on 999  degrees of freedom</span>
<span class="co">#&gt; Residual deviance:   77.243  on 998  degrees of freedom</span>
<span class="co">#&gt; AIC: 81.243</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 11</span></code></pre></div>
<p>One reason that logistic regression can be a bit tricky initially, is because the coefficients take a bit of work to interpret. In particular, our estimate on likelihood of it being night is 0.91 This is the odds. So, the odds that it is night, increase by 0.91 as the number of cars that we saw increases. We can translate the result into probabilities using <code><a href="https://generics.r-lib.org/reference/augment.html">augment()</a></code> from <code>broom</code> <span class="citation">(<a href="references-1.html#ref-broom" role="doc-biblioref">D. Robinson, Hayes, and Couch 2021</a>)</span> and this allows us to graph the results (Figure <a href="ijalm.html#fig:dayornightprobs">14.7</a>).</p>
<div class="sourceCode" id="cb479"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://broom.tidymodels.org/">broom</a></span><span class="op">)</span>

<span class="va">day_or_night</span> <span class="op">&lt;-</span>
  <span class="fu"><a href="https://generics.r-lib.org/reference/augment.html">augment</a></span><span class="op">(</span><span class="va">day_or_night_model</span>,
          data <span class="op">=</span> <span class="va">day_or_night</span>,
          type.predict <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span>

<span class="va">day_or_night</span>
<span class="co">#&gt; # A tibble: 1,000 × 8</span>
<span class="co">#&gt;    number_of_cars is_night  .fitted        .resid .std.resid</span>
<span class="co">#&gt;             &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;</span>
<span class="co">#&gt;  1             36        0 3.06e- 6 -0.00247        -2.47e-3</span>
<span class="co">#&gt;  2             12        0 2.22e-16 -0.0000000211   -2.11e-8</span>
<span class="co">#&gt;  3             48        0 1.48e- 1 -0.565          -5.71e-1</span>
<span class="co">#&gt;  4             32        0 7.95e- 8 -0.000399       -3.99e-4</span>
<span class="co">#&gt;  5              4        0 2.22e-16 -0.0000000211   -2.11e-8</span>
<span class="co">#&gt;  6             40        0 1.17e- 4 -0.0153         -1.53e-2</span>
<span class="co">#&gt;  7             13        0 2.22e-16 -0.0000000211   -2.11e-8</span>
<span class="co">#&gt;  8             24        0 5.39e-11 -0.0000104      -1.04e-5</span>
<span class="co">#&gt;  9             16        0 2.22e-16 -0.0000000211   -2.11e-8</span>
<span class="co">#&gt; 10             19        0 5.63e-13 -0.00000106     -1.06e-6</span>
<span class="co">#&gt; # … with 990 more rows, and 3 more variables: .hat &lt;dbl&gt;,</span>
<span class="co">#&gt; #   .sigma &lt;dbl&gt;, .cooksd &lt;dbl&gt;</span></code></pre></div>
<div class="sourceCode" id="cb480"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">day_or_night</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>is_night <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">is_night</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">number_of_cars</span>,
             y <span class="op">=</span> <span class="va">.fitted</span>,
             color <span class="op">=</span> <span class="va">is_night</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_jitter.html">geom_jitter</a></span><span class="op">(</span>width <span class="op">=</span> <span class="fl">0.01</span>, height <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Number of cars that were seen"</span>,
       y <span class="op">=</span> <span class="st">"Estimated probability it is night"</span>,
       color <span class="op">=</span> <span class="st">"Was actually night"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_brewer.html">scale_color_brewer</a></span><span class="op">(</span>palette <span class="op">=</span> <span class="st">"Set1"</span><span class="op">)</span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:dayornightprobs"></span>
<img src="41-ijalm_files/figure-html/dayornightprobs-1.png" alt="Logistic regression probability results with simulated data of whether it is day or night based on the number of cars that are around" width="672"><p class="caption">
Figure 14.7: Logistic regression probability results with simulated data of whether it is day or night based on the number of cars that are around
</p>
</div>
<p>We can use <code>tidymodels</code> to run this if we wanted. In order to do that, we first need to change the class of our dependent variable into a factor.</p>
<div class="sourceCode" id="cb481"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">853</span><span class="op">)</span>

<span class="va">day_or_night</span> <span class="op">&lt;-</span>
  <span class="va">day_or_night</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>is_night <span class="op">=</span> <span class="fu"><a href="https://forcats.tidyverse.org/reference/as_factor.html">as_factor</a></span><span class="op">(</span><span class="va">is_night</span><span class="op">)</span><span class="op">)</span>

<span class="va">day_or_night_split</span> <span class="op">&lt;-</span> <span class="fu">initial_split</span><span class="op">(</span><span class="va">day_or_night</span>, prop <span class="op">=</span> <span class="fl">0.80</span><span class="op">)</span>
<span class="va">day_or_night_train</span> <span class="op">&lt;-</span> <span class="fu">training</span><span class="op">(</span><span class="va">day_or_night_split</span><span class="op">)</span>
<span class="va">day_or_night_test</span> <span class="op">&lt;-</span> <span class="fu">testing</span><span class="op">(</span><span class="va">day_or_night_split</span><span class="op">)</span>

<span class="va">day_or_night_tidymodels</span> <span class="op">&lt;-</span>
  <span class="fu">logistic_reg</span><span class="op">(</span>mode <span class="op">=</span> <span class="st">"classification"</span><span class="op">)</span> |&gt;
  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"glm"</span><span class="op">)</span> |&gt;
  <span class="fu">fit</span><span class="op">(</span><span class="va">is_night</span> <span class="op">~</span> <span class="va">number_of_cars</span>,
      data <span class="op">=</span> <span class="va">day_or_night_train</span><span class="op">)</span>
<span class="co">#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1</span>
<span class="co">#&gt; occurred</span>

<span class="va">day_or_night_tidymodels</span>
<span class="co">#&gt; parsnip model object</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Fit time:  5ms </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:  stats::glm(formula = is_night ~ number_of_cars, family = stats::binomial, </span>
<span class="co">#&gt;     data = data)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;    (Intercept)  number_of_cars  </span>
<span class="co">#&gt;       -44.4817          0.8937  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Degrees of Freedom: 799 Total (i.e. Null);  798 Residual</span>
<span class="co">#&gt; Null Deviance:       1109 </span>
<span class="co">#&gt; Residual Deviance: 62.5  AIC: 66.5</span></code></pre></div>
<p>As before, we can make a graph of the actual results compared with our estimates. But one nice aspect of this is that we could use our test dataset to more thoroughly evaluate our model’s forecasting ability, for instance through a confusion matrix. We find that the model does well on the held-out dataset.</p>
<div class="sourceCode" id="cb482"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">day_or_night_tidymodels</span> |&gt;
  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span>new_data <span class="op">=</span> <span class="va">day_or_night_test</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">day_or_night_test</span><span class="op">)</span> |&gt;
  <span class="fu">conf_mat</span><span class="op">(</span>truth <span class="op">=</span> <span class="va">is_night</span>, estimate <span class="op">=</span> <span class="va">.pred_class</span><span class="op">)</span>
<span class="co">#&gt;           Truth</span>
<span class="co">#&gt; Prediction   0   1</span>
<span class="co">#&gt;          0  95   0</span>
<span class="co">#&gt;          1   3 102</span></code></pre></div>
<p>Finally, we might be interested in inference, and so want to build a Bayesian model using <code>rstanarm</code>. Again, we will more fully specify our model:</p>
<p>Finally, we can build a Bayesian model and estimate it with <code>rstanarm</code>.</p>
<p><span class="math display">\[
\begin{aligned}
\mbox{Pr}(y_i=1) &amp; = \mbox{logit}^{-1}\left(\beta_0+\beta_1 x_i\right)\\
\beta_0 &amp; \sim \mbox{Normal}(0, 3)\\
\beta_1 &amp; \sim \mbox{Normal}(0, 3)
\end{aligned}
\]</span></p>
<div class="sourceCode" id="cb483"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">day_or_night_rstanarm</span> <span class="op">&lt;-</span>
  <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span>
    <span class="va">is_night</span> <span class="op">~</span> <span class="va">number_of_cars</span>,
    data <span class="op">=</span> <span class="va">day_or_night</span>,
    family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span>,
    prior <span class="op">=</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/priors.html">normal</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">3</span><span class="op">)</span>,
    prior_intercept <span class="op">=</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/priors.html">normal</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">3</span><span class="op">)</span>,
    seed <span class="op">=</span> <span class="fl">853</span>
  <span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/readRDS.html">saveRDS</a></span><span class="op">(</span><span class="va">day_or_night_rstanarm</span>,
        file <span class="op">=</span> <span class="st">"day_or_night_rstanarm.rds"</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb484"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">day_or_night_rstanarm</span>
<span class="co">#&gt; stan_glm</span>
<span class="co">#&gt;  family:       binomial [logit]</span>
<span class="co">#&gt;  formula:      is_night ~ number_of_cars</span>
<span class="co">#&gt;  observations: 1000</span>
<span class="co">#&gt;  predictors:   2</span>
<span class="co">#&gt; ------</span>
<span class="co">#&gt;                Median MAD_SD</span>
<span class="co">#&gt; (Intercept)    -47.3    8.0 </span>
<span class="co">#&gt; number_of_cars   0.9    0.2 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; ------</span>
<span class="co">#&gt; * For help interpreting the printed output see ?print.stanreg</span>
<span class="co">#&gt; * For info on the priors used see ?prior_summary.stanreg</span></code></pre></div>
</div>
<div id="poisson-regression" class="section level2" number="14.5">
<h2>
<span class="header-section-number">14.5</span> Poisson regression<a class="anchor" aria-label="anchor" href="#poisson-regression"><i class="fas fa-link"></i></a>
</h2>
<p>When we have count data, we should initially think to use Poisson distribution. The Poisson distribution has the interesting feature that the mean is also the variance, and so as the mean increases, so does the variance. As such, the Poisson distribution is governed by the parameter, <span class="math inline">\(\lambda\)</span> and it distributes probabilities over the non-negative integers. The Poisson distribution is <span class="citation">(<a href="references-1.html#ref-pitman" role="doc-biblioref">Pitman 1993, 121</a>)</span>:</p>
<p><span class="math display">\[P_{\lambda}(k) = e^{-\lambda}\mu^k/k!\mbox{, for }k=0,1,2,...\]</span>
We can simulate <span class="math inline">\(n=20\)</span> draws from the Poisson distribution with <code><a href="https://rdrr.io/r/stats/Poisson.html">rpois()</a></code>, where <span class="math inline">\(\lambda\)</span> is both the mean and the variance. The <span class="math inline">\(\lambda\)</span> parameter governs the shape of the distribution (Figure <a href="ijalm.html#fig:poissondistributiontakingshape">14.8</a>).</p>
<div class="sourceCode" id="cb485"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">rpois</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">20</span>, lambda <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="co">#&gt;  [1] 1 5 5 4 5 2 1 4 5 4 6 2 3 4 4 6 5 1 3 5</span></code></pre></div>
<div class="sourceCode" id="cb486"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">853</span><span class="op">)</span>

<span class="va">number_of_each</span> <span class="op">&lt;-</span> <span class="fl">1000</span>

<span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>
  lambda <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>
    <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">number_of_each</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">number_of_each</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">2</span>, <span class="va">number_of_each</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">4</span>, <span class="va">number_of_each</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">7</span>, <span class="va">number_of_each</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">10</span>, <span class="va">number_of_each</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">15</span>, <span class="va">number_of_each</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">50</span>, <span class="va">number_of_each</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">100</span>, <span class="va">number_of_each</span><span class="op">)</span>
  <span class="op">)</span>,
  draw <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>
    <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">rpois</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">number_of_each</span>, lambda <span class="op">=</span> <span class="fl">0</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">rpois</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">number_of_each</span>, lambda <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">rpois</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">number_of_each</span>, lambda <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">rpois</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">number_of_each</span>, lambda <span class="op">=</span> <span class="fl">4</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">rpois</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">number_of_each</span>, lambda <span class="op">=</span> <span class="fl">7</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">rpois</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">number_of_each</span>, lambda <span class="op">=</span> <span class="fl">10</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">rpois</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">number_of_each</span>, lambda <span class="op">=</span> <span class="fl">15</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">rpois</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">number_of_each</span>, lambda <span class="op">=</span> <span class="fl">50</span><span class="op">)</span>,
    <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">rpois</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">number_of_each</span>, lambda <span class="op">=</span> <span class="fl">100</span><span class="op">)</span>
  <span class="op">)</span>
<span class="op">)</span> |&gt;
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">draw</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_density.html">geom_density</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/vars.html">vars</a></span><span class="op">(</span><span class="va">lambda</span><span class="op">)</span>,
             scales <span class="op">=</span> <span class="st">"free_y"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">'Integer'</span>,
       y <span class="op">=</span> <span class="st">'Density'</span><span class="op">)</span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:poissondistributiontakingshape"></span>
<img src="41-ijalm_files/figure-html/poissondistributiontakingshape-1.png" alt="The Poisson distribution is governed by the value of the mean, which is the same as its variance" width="672"><p class="caption">
Figure 14.8: The Poisson distribution is governed by the value of the mean, which is the same as its variance
</p>
</div>
<p>For instance, if we look at the number of A+ grades that are awarded in each university course in a given term then for each course we would have a count.</p>
<div class="sourceCode" id="cb487"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">853</span><span class="op">)</span>

<span class="va">count_of_A_plus</span> <span class="op">&lt;-</span>
  <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>
    <span class="co"># Thanks to Chris DuBois: https://stackoverflow.com/a/1439843</span>
    department <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep.int</a></span><span class="op">(</span><span class="st">"1"</span>, <span class="fl">26</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep.int</a></span><span class="op">(</span><span class="st">"2"</span>, <span class="fl">26</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep.int</a></span><span class="op">(</span><span class="st">"3"</span>, <span class="fl">26</span><span class="op">)</span><span class="op">)</span>,
    course <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"DEP_1_"</span>, <span class="va">letters</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"DEP_2_"</span>, <span class="va">letters</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"DEP_3_"</span>, <span class="va">letters</span><span class="op">)</span><span class="op">)</span>,
    number_of_A_plus <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>
      <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">)</span>,
             size <span class="op">=</span> <span class="fl">26</span>,
             replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,
      <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">50</span><span class="op">)</span>,
             size <span class="op">=</span> <span class="fl">26</span>,
             replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,
      <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">25</span><span class="op">)</span>,
             size <span class="op">=</span> <span class="fl">26</span>,
             replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
    <span class="op">)</span>
  <span class="op">)</span>

<span class="va">count_of_A_plus</span>
<span class="co">#&gt; # A tibble: 78 × 3</span>
<span class="co">#&gt;    department course  number_of_A_plus</span>
<span class="co">#&gt;    &lt;chr&gt;      &lt;chr&gt;              &lt;int&gt;</span>
<span class="co">#&gt;  1 1          DEP_1_a                9</span>
<span class="co">#&gt;  2 1          DEP_1_b               10</span>
<span class="co">#&gt;  3 1          DEP_1_c                1</span>
<span class="co">#&gt;  4 1          DEP_1_d                5</span>
<span class="co">#&gt;  5 1          DEP_1_e                2</span>
<span class="co">#&gt;  6 1          DEP_1_f                4</span>
<span class="co">#&gt;  7 1          DEP_1_g                3</span>
<span class="co">#&gt;  8 1          DEP_1_h                3</span>
<span class="co">#&gt;  9 1          DEP_1_i                1</span>
<span class="co">#&gt; 10 1          DEP_1_j                3</span>
<span class="co">#&gt; # … with 68 more rows</span></code></pre></div>
<p>Our simulated dataset has the number of A+ grades awarded by courses, which are structured within departments. We can use <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code> and <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> from base to quickly get a sense of the data.</p>
<div class="sourceCode" id="cb488"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">grades_model_base</span> <span class="op">&lt;-</span> 
  <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">number_of_A_plus</span> <span class="op">~</span> <span class="va">department</span>, 
    data <span class="op">=</span> <span class="va">count_of_A_plus</span>, 
    family <span class="op">=</span> <span class="st">'poisson'</span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">grades_model_base</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = number_of_A_plus ~ department, family = "poisson", </span>
<span class="co">#&gt;     data = count_of_A_plus)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt; -6.739  -1.210  -0.171   1.424   3.952  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)  1.44238    0.09535  15.128   &lt;2e-16 ***</span>
<span class="co">#&gt; department2  1.85345    0.10254  18.075   &lt;2e-16 ***</span>
<span class="co">#&gt; department3  1.00663    0.11141   9.035   &lt;2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  </span>
<span class="co">#&gt; 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for poisson family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 952.12  on 77  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 450.08  on 75  degrees of freedom</span>
<span class="co">#&gt; AIC: 768.21</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 5</span></code></pre></div>
<p>The interpretation of the coefficient on ‘department2’ is that it is the log of the expected difference between departments. So we expect <span class="math inline">\(\exp(1.85345) \approx 6.3\)</span> and <span class="math inline">\(\exp(1.00663) \approx 2.7\)</span> additional A+ grades in departments 2 and 3, compared with department 1.</p>
<p>We can use <code>tidymodels</code> to estimate Poisson regression models with <code>poissonreg</code> <span class="citation">(<a href="references-1.html#ref-poissonreg" role="doc-biblioref">Kuhn 2021</a>)</span>.</p>
<div class="sourceCode" id="cb489"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/tidymodels/poissonreg">poissonreg</a></span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">853</span><span class="op">)</span>

<span class="va">count_of_A_plus_split</span> <span class="op">&lt;-</span>
  <span class="fu">rsample</span><span class="fu">::</span><span class="fu"><a href="https://rsample.tidymodels.org/reference/initial_split.html">initial_split</a></span><span class="op">(</span><span class="va">count_of_A_plus</span>, prop <span class="op">=</span> <span class="fl">0.80</span><span class="op">)</span>
<span class="va">count_of_A_plus_train</span> <span class="op">&lt;-</span> <span class="fu">rsample</span><span class="fu">::</span><span class="fu"><a href="https://rsample.tidymodels.org/reference/initial_split.html">training</a></span><span class="op">(</span><span class="va">count_of_A_plus_split</span><span class="op">)</span>
<span class="va">count_of_A_plus_test</span> <span class="op">&lt;-</span> <span class="fu">rsample</span><span class="fu">::</span><span class="fu"><a href="https://rsample.tidymodels.org/reference/initial_split.html">testing</a></span><span class="op">(</span><span class="va">count_of_A_plus_split</span><span class="op">)</span>

<span class="va">a_plus_model_tidymodels</span> <span class="op">&lt;-</span>
  <span class="fu"><a href="https://poissonreg.tidymodels.org/reference/poisson_reg.html">poisson_reg</a></span><span class="op">(</span>mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_engine.html">set_engine</a></span><span class="op">(</span><span class="st">"glm"</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span><span class="va">number_of_A_plus</span> <span class="op">~</span> <span class="va">department</span>,
      data <span class="op">=</span> <span class="va">count_of_A_plus_train</span><span class="op">)</span>

<span class="va">a_plus_model_tidymodels</span>
<span class="co">#&gt; parsnip model object</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Fit time:  3ms </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:  stats::glm(formula = number_of_A_plus ~ department, family = stats::poisson, </span>
<span class="co">#&gt;     data = data)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt; (Intercept)  department2  department3  </span>
<span class="co">#&gt;       1.470        1.925        1.011  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Degrees of Freedom: 61 Total (i.e. Null);  59 Residual</span>
<span class="co">#&gt; Null Deviance:       758 </span>
<span class="co">#&gt; Residual Deviance: 276.8     AIC: 534.8</span></code></pre></div>
<p>And finally, we can build a Bayesian model and estimate it with <code>rstanarm</code>. We put a tight prior on the coefficients because of the propensity for the Poisson distribution to expand them substantially.</p>
<p><span class="math display">\[
\begin{aligned}
y_i &amp;\sim \mbox{Poisson}(\lambda_i)\\
\log(\lambda_i) &amp; = \beta_0 + \beta_1 x_1 + \beta_2 x_2\\
\beta_0 &amp; \sim \mbox{Normal}(0, 0.5)\\
\beta_1 &amp; \sim \mbox{Normal}(0, 0.5)\\
\beta_2 &amp; \sim \mbox{Normal}(0, 0.5)
\end{aligned}
\]</span></p>
<div class="sourceCode" id="cb490"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">count_of_A_plus_rstanarm</span> <span class="op">&lt;-</span>
  <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span>
    <span class="va">number_of_A_plus</span> <span class="op">~</span> <span class="va">department</span>,
    data <span class="op">=</span> <span class="va">count_of_A_plus</span>,
    family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">poisson</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"log"</span><span class="op">)</span>,
    prior <span class="op">=</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/priors.html">normal</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.5</span><span class="op">)</span>,
    prior_intercept <span class="op">=</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/priors.html">normal</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.5</span><span class="op">)</span>,
    seed <span class="op">=</span> <span class="fl">853</span>
  <span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/readRDS.html">saveRDS</a></span><span class="op">(</span><span class="va">count_of_A_plus_rstanarm</span>,
        file <span class="op">=</span> <span class="st">"count_of_A_plus_rstanarm.rds"</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb491"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">count_of_A_plus_rstanarm</span>
<span class="co">#&gt; stan_glm</span>
<span class="co">#&gt;  family:       poisson [log]</span>
<span class="co">#&gt;  formula:      number_of_A_plus ~ department</span>
<span class="co">#&gt;  observations: 78</span>
<span class="co">#&gt;  predictors:   3</span>
<span class="co">#&gt; ------</span>
<span class="co">#&gt;             Median MAD_SD</span>
<span class="co">#&gt; (Intercept) 1.5    0.1   </span>
<span class="co">#&gt; department2 1.8    0.1   </span>
<span class="co">#&gt; department3 0.9    0.1   </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; ------</span>
<span class="co">#&gt; * For help interpreting the printed output see ?print.stanreg</span>
<span class="co">#&gt; * For info on the priors used see ?prior_summary.stanreg</span></code></pre></div>
<!-- ## Proportional hazards -->
<!-- Could do like how long someone has to wait for something? -->
</div>
<div id="exercises-and-tutorial-13" class="section level2" number="14.6">
<h2>
<span class="header-section-number">14.6</span> Exercises and tutorial<a class="anchor" aria-label="anchor" href="#exercises-and-tutorial-13"><i class="fas fa-link"></i></a>
</h2>
<div id="exercises-13" class="section level3" number="14.6.1">
<h3>
<span class="header-section-number">14.6.1</span> Exercises<a class="anchor" aria-label="anchor" href="#exercises-13"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li>Please write a linear relationship between some response variable, Y, and some predictor, X. What is the intercept term? What is the slope term? What would adding a hat to these indicate?</li>
<li>What is the least squares criterion? Similarly, what is RSS and what are we trying to do when we run least squares regression?</li>
<li>What is statistical bias?</li>
<li>If there were three variables: Snow, Temperature, and Wind, please write R code that would fit a simple linear regression to explain Snow as a function of Temperature and Wind. What do you think about another explanatory variable - daily stock market returns - to your model?</li>
<li>According to <span class="citation">Greenland et al. (<a href="references-1.html#ref-greenland2016statistical" role="doc-biblioref">2016</a>)</span>, p-values test (pick one)?
<ol style="list-style-type: lower-alpha">
<li>All the assumptions about how the data were generated (the entire model), not just the targeted hypothesis it is supposed to test (such as a null hypothesis).</li>
<li>Whether the hypothesis targeted for testing is true or not.</li>
<li>A dichotomy whereby results can be declared ‘statistically significant’.</li>
</ol>
</li>
<li>According to <span class="citation">Greenland et al. (<a href="references-1.html#ref-greenland2016statistical" role="doc-biblioref">2016</a>)</span>, a p-value may be small because (select all)?
<ol style="list-style-type: lower-alpha">
<li>The targeted hypothesis is false.</li>
<li>The study protocols were violated.</li>
<li>It was selected for presentation based on its small size.</li>
</ol>
</li>
<li>According to <span class="citation">Obermeyer et al. (<a href="references-1.html#ref-obermeyer2019dissecting" role="doc-biblioref">2019</a>)</span>, why does racial bias occur in an algorithm used to guide health decisions in the US (pick one)?
<ol style="list-style-type: lower-alpha">
<li>The algorithm uses health costs as a proxy for health needs.</li>
<li>The algorithm was trained on Reddit data.</li>
</ol>
</li>
<li>When should we use logistic regression (pick one)?
<ol style="list-style-type: lower-alpha">
<li>Continuous dependent variable.</li>
<li>Binary dependent variable.</li>
<li>Count dependent variable.</li>
</ol>
</li>
<li>We are interested in studying how voting intentions in the recent US presidential election vary by an individual’s income. We set up a logistic regression model to study this relationship. In this study, one possible dependent variable would be (pick one)?
<ol style="list-style-type: lower-alpha">
<li>Whether the respondent is a US citizen (yes/no)</li>
<li>The respondent’s personal income (high/low)</li>
<li>Whether the respondent is going to vote for Trump (yes/no)</li>
<li>Who the respondent voted for in 2016 (Trump/Clinton)</li>
</ol>
</li>
<li>We are interested in studying how voting intentions in the recent US presidential election vary by an individual’s income. We set up a logistic regression model to study this relationship. In this study, one possible dependent variable would be (pick one)?
<ol style="list-style-type: lower-alpha">
<li>The race of the respondent (white/not white)</li>
<li>The respondent’s marital status (married/not)</li>
<li>Whether the respondent is registered to vote (yes/no)</li>
<li>Whether the respondent is going to vote for Biden (yes/no)</li>
</ol>
</li>
<li>Please explain what a p-value is, using only the term itself (i.e. ‘p-value’) and words that are amongst the 1,000 most common in the English language according to the XKCD Simple Writer - <a href="https://xkcd.com/simplewriter/" class="uri">https://xkcd.com/simplewriter/</a>. (Please write one or two paragraphs.)</li>
<li>The mean of a Poisson distribution is equal to its?
<ol style="list-style-type: lower-alpha">
<li>Median.</li>
<li>Standard deviation.</li>
<li>Variance.</li>
</ol>
</li>
<li>What is power (in a statistical context)?</li>
<li>According to <span class="citation">McElreath (<a href="references-1.html#ref-citemcelreath" role="doc-biblioref">2020, 162</a>)</span> ‘Regression will not sort it out. Regression is indeed an oracle, but a cruel one. It speaks in riddles and delights in punishing us for…’ (please select one answer)?
<ol style="list-style-type: lower-alpha">
<li>overcomplicating models.</li>
<li>asking bad questions.</li>
<li>using bad data.</li>
</ol>
</li>
<li>Is a model that fits the small or large world more important to you, and why?</li>
</ol>
</div>
<div id="tutorial-13" class="section level3" number="14.6.2">
<h3>
<span class="header-section-number">14.6.2</span> Tutorial<a class="anchor" aria-label="anchor" href="#tutorial-13"><i class="fas fa-link"></i></a>
</h3>
<p>Simulate some data that are similar to those discussed by <span class="citation">Gould (<a href="references-1.html#ref-gould2013median" role="doc-biblioref">2013</a>)</span>. Then build a regression model. Discuss your results</p>
</div>
<div id="paper-4" class="section level3" number="14.6.3">
<h3>
<span class="header-section-number">14.6.3</span> Paper<a class="anchor" aria-label="anchor" href="#paper-4"><i class="fas fa-link"></i></a>
</h3>
<p>At about this point, Paper Four (Appendix <a href="papers.html#paper-four">B.4</a>) would be appropriate.</p>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="exploratory-data-analysis.html"><span class="header-section-number">13</span> Exploratory data analysis</a></div>
<div class="next"><a href="causality.html"><span class="header-section-number">15</span> Causality from observational data</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#ijalm"><span class="header-section-number">14</span> It’s Just A Linear Model</a></li>
<li><a class="nav-link" href="#introduction-11"><span class="header-section-number">14.1</span> Introduction</a></li>
<li><a class="nav-link" href="#simple-linear-regression"><span class="header-section-number">14.2</span> Simple linear regression</a></li>
<li><a class="nav-link" href="#multiple-linear-regression"><span class="header-section-number">14.3</span> Multiple linear regression</a></li>
<li><a class="nav-link" href="#logistic-regression"><span class="header-section-number">14.4</span> Logistic regression</a></li>
<li><a class="nav-link" href="#poisson-regression"><span class="header-section-number">14.5</span> Poisson regression</a></li>
<li>
<a class="nav-link" href="#exercises-and-tutorial-13"><span class="header-section-number">14.6</span> Exercises and tutorial</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#exercises-13"><span class="header-section-number">14.6.1</span> Exercises</a></li>
<li><a class="nav-link" href="#tutorial-13"><span class="header-section-number">14.6.2</span> Tutorial</a></li>
<li><a class="nav-link" href="#paper-4"><span class="header-section-number">14.6.3</span> Paper</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/rstudio/bookdown-demo/blob/master/41-ijalm.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/rstudio/bookdown-demo/edit/master/41-ijalm.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Telling Stories With Data</strong>" was written by Rohan Alexander. It was last built on 16 March, 2022.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
